{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Scraper de headlines do Investing.com (PT-BR) por empresa.\n",
    "Lê um Excel (BaseRefAtivos.xlsx) com:\n",
    "  Empresa | Setor | Ticker BDR | Ticker Original (EUA) | Bolsa (EUA) | Link News\n",
    "\n",
    "Saída: Parquet com colunas:\n",
    "  id, datetime, source, headline, ticker, sector, country, url, language\n",
    "\n",
    "Destaques de debug:\n",
    "- logging com níveis, --verbose/--debug\n",
    "- --only para filtrar por ticker ou empresa\n",
    "- --max-pages (padrão 15) para smoke test\n",
    "- --save-html-debug salva HTML bruto de páginas em ./_html_debug\n",
    "- retries com backoff/jitter e tratamento de 429/5xx\n",
    "- checkpoint incremental (--resume): mescla com parquet existente e evita retrabalho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:28:54 | INFO    | Excel: /Users/emanuelgandra/Desktop/Projetos /TesteQuant/BaseRefAtivos.xlsx\n",
      "22:28:54 | INFO    | Saída: /Users/emanuelgandra/Desktop/Projetos /TesteQuant/investing_news.parquet\n",
      "22:28:54 | INFO    | Limite de páginas: 780\n",
      "Empresas:   0%|          | 0/43 [00:00<?, ?it/s]22:28:56 | INFO    | [AAPL] p1: 10 items.\n",
      "22:28:57 | INFO    | [AAPL] p2: 10 items.\n",
      "22:29:00 | INFO    | [AAPL] p3: 10 items.\n",
      "22:29:02 | INFO    | [AAPL] p4: 10 items.\n",
      "22:29:03 | INFO    | [AAPL] p5: 10 items.\n",
      "22:29:05 | INFO    | [AAPL] p6: 10 items.\n",
      "22:29:07 | INFO    | [AAPL] p7: 10 items.\n",
      "22:29:09 | INFO    | [AAPL] p8: 10 items.\n",
      "22:29:11 | INFO    | [AAPL] p9: 10 items.\n",
      "22:29:13 | INFO    | [AAPL] p10: 10 items.\n",
      "22:29:15 | INFO    | [AAPL] p11: 10 items.\n",
      "22:29:17 | INFO    | [AAPL] p12: 10 items.\n",
      "22:29:19 | INFO    | [AAPL] p13: 10 items.\n",
      "22:29:21 | INFO    | [AAPL] p14: 10 items.\n",
      "22:29:22 | INFO    | [AAPL] p15: 10 items.\n",
      "22:29:24 | INFO    | [AAPL] p16: 10 items.\n",
      "22:29:26 | INFO    | [AAPL] p17: 10 items.\n",
      "22:29:28 | INFO    | [AAPL] p18: 10 items.\n",
      "22:29:30 | INFO    | [AAPL] p19: 10 items.\n",
      "22:29:32 | INFO    | [AAPL] p20: 10 items.\n",
      "22:29:34 | INFO    | [AAPL] p21: 10 items.\n",
      "22:29:36 | INFO    | [AAPL] p22: 10 items.\n",
      "22:29:38 | INFO    | [AAPL] p23: 10 items.\n",
      "22:29:40 | INFO    | [AAPL] p24: 10 items.\n",
      "22:29:41 | INFO    | [AAPL] p25: 10 items.\n",
      "22:29:43 | INFO    | [AAPL] p26: 10 items.\n",
      "22:29:45 | INFO    | [AAPL] p27: 10 items.\n",
      "22:29:47 | INFO    | [AAPL] p28: 10 items.\n",
      "22:29:49 | INFO    | [AAPL] p29: 10 items.\n",
      "22:29:51 | INFO    | [AAPL] p30: 10 items.\n",
      "22:29:53 | INFO    | [AAPL] p31: 10 items.\n",
      "22:29:55 | INFO    | [AAPL] p32: 10 items.\n",
      "22:29:57 | INFO    | [AAPL] p33: 10 items.\n",
      "22:29:59 | INFO    | [AAPL] p34: 10 items.\n",
      "22:30:01 | INFO    | [AAPL] p35: 10 items.\n",
      "22:30:03 | INFO    | [AAPL] p36: 10 items.\n",
      "22:30:05 | INFO    | [AAPL] p37: 10 items.\n",
      "22:30:06 | INFO    | [AAPL] p38: 10 items.\n",
      "22:30:08 | INFO    | [AAPL] p39: 10 items.\n",
      "22:30:11 | INFO    | [AAPL] p40: 10 items.\n",
      "22:30:13 | INFO    | [AAPL] p41: 10 items.\n",
      "22:30:15 | INFO    | [AAPL] p42: 10 items.\n",
      "22:30:17 | INFO    | [AAPL] p43: 10 items.\n",
      "22:30:19 | INFO    | [AAPL] p44: 10 items.\n",
      "22:30:21 | INFO    | [AAPL] p45: 10 items.\n",
      "22:30:22 | INFO    | [AAPL] p46: 10 items.\n",
      "22:30:24 | INFO    | [AAPL] p47: 10 items.\n",
      "22:30:26 | INFO    | [AAPL] p48: 10 items.\n",
      "22:30:28 | INFO    | [AAPL] p49: 10 items.\n",
      "22:30:30 | INFO    | [AAPL] p50: 10 items.\n",
      "22:30:31 | INFO    | [AAPL] p51: 10 items.\n",
      "22:30:33 | INFO    | [AAPL] p52: 10 items.\n",
      "22:30:35 | INFO    | [AAPL] p53: 10 items.\n",
      "22:30:37 | INFO    | [AAPL] p54: 10 items.\n",
      "22:30:39 | INFO    | [AAPL] p55: 10 items.\n",
      "22:30:41 | INFO    | [AAPL] p56: 10 items.\n",
      "22:30:43 | INFO    | [AAPL] p57: 10 items.\n",
      "22:30:45 | INFO    | [AAPL] p58: 10 items.\n",
      "22:30:47 | INFO    | [AAPL] p59: 10 items.\n",
      "22:30:49 | INFO    | [AAPL] p60: 10 items.\n",
      "22:30:51 | INFO    | [AAPL] p61: 10 items.\n",
      "22:30:53 | INFO    | [AAPL] p62: 10 items.\n",
      "22:30:55 | INFO    | [AAPL] p63: 10 items.\n",
      "22:30:56 | INFO    | [AAPL] p64: 10 items.\n",
      "22:30:58 | INFO    | [AAPL] p65: 10 items.\n",
      "22:31:00 | INFO    | [AAPL] p66: 10 items.\n",
      "22:31:02 | INFO    | [AAPL] p67: 10 items.\n",
      "22:31:04 | INFO    | [AAPL] p68: 10 items.\n",
      "22:31:05 | INFO    | [AAPL] p69: 10 items.\n",
      "22:31:07 | INFO    | [AAPL] p70: 10 items.\n",
      "22:31:09 | INFO    | [AAPL] p71: 10 items.\n",
      "22:31:11 | INFO    | [AAPL] p72: 10 items.\n",
      "22:31:13 | INFO    | [AAPL] p73: 10 items.\n",
      "22:31:14 | INFO    | [AAPL] p74: 10 items.\n",
      "22:31:17 | INFO    | [AAPL] p75: 10 items.\n",
      "22:31:19 | INFO    | [AAPL] p76: 10 items.\n",
      "22:31:21 | INFO    | [AAPL] p77: 10 items.\n",
      "22:31:23 | INFO    | [AAPL] p78: 10 items.\n",
      "22:31:25 | INFO    | [AAPL] p79: 10 items.\n",
      "22:31:27 | INFO    | [AAPL] p80: 10 items.\n",
      "22:31:28 | INFO    | [AAPL] p81: 10 items.\n",
      "22:31:31 | INFO    | [AAPL] p82: 10 items.\n",
      "22:31:33 | INFO    | [AAPL] p83: 10 items.\n",
      "22:31:36 | INFO    | [AAPL] p84: 10 items.\n",
      "22:31:38 | INFO    | [AAPL] p85: 10 items.\n",
      "22:31:40 | INFO    | [AAPL] p86: 10 items.\n",
      "22:31:42 | INFO    | [AAPL] p87: 10 items.\n",
      "22:31:44 | INFO    | [AAPL] p88: 10 items.\n",
      "22:31:46 | INFO    | [AAPL] p89: 10 items.\n",
      "22:31:48 | INFO    | [AAPL] p90: 10 items.\n",
      "22:31:50 | INFO    | [AAPL] p91: 10 items.\n",
      "22:31:52 | INFO    | [AAPL] p92: 10 items.\n",
      "22:31:54 | INFO    | [AAPL] p93: 10 items.\n",
      "22:31:56 | INFO    | [AAPL] p94: 10 items.\n",
      "22:31:58 | INFO    | [AAPL] p95: 10 items.\n",
      "22:32:00 | INFO    | [AAPL] p96: 10 items.\n",
      "22:32:02 | INFO    | [AAPL] p97: 10 items.\n",
      "22:32:05 | INFO    | [AAPL] p98: 10 items.\n",
      "22:32:06 | INFO    | [AAPL] p99: 10 items.\n",
      "22:32:08 | INFO    | [AAPL] p100: 10 items.\n",
      "22:32:10 | INFO    | [AAPL] p101: 10 items.\n",
      "22:32:13 | INFO    | [AAPL] p102: 10 items.\n",
      "22:32:15 | INFO    | [AAPL] p103: 10 items.\n",
      "22:32:18 | INFO    | [AAPL] p104: 10 items.\n",
      "22:32:20 | INFO    | [AAPL] p105: 10 items.\n",
      "22:32:22 | INFO    | [AAPL] p106: 10 items.\n",
      "22:32:24 | INFO    | [AAPL] p107: 10 items.\n",
      "22:32:26 | INFO    | [AAPL] p108: 10 items.\n",
      "22:32:28 | INFO    | [AAPL] p109: 10 items.\n",
      "22:32:30 | INFO    | [AAPL] p110: 10 items.\n",
      "22:32:32 | INFO    | [AAPL] p111: 10 items.\n",
      "22:32:34 | INFO    | [AAPL] p112: 10 items.\n",
      "22:32:36 | INFO    | [AAPL] p113: 10 items.\n",
      "22:32:38 | INFO    | [AAPL] p114: 10 items.\n",
      "22:32:42 | INFO    | [AAPL] p115: 10 items.\n",
      "22:32:44 | INFO    | [AAPL] p116: 10 items.\n",
      "22:32:46 | INFO    | [AAPL] p117: 10 items.\n",
      "22:32:48 | INFO    | [AAPL] p118: 10 items.\n",
      "22:32:49 | INFO    | [AAPL] p119: 10 items.\n",
      "22:32:51 | INFO    | [AAPL] p120: 10 items.\n",
      "22:32:53 | INFO    | [AAPL] p121: 10 items.\n",
      "22:32:55 | INFO    | [AAPL] p122: 10 items.\n",
      "22:32:56 | INFO    | [AAPL] p123: 10 items.\n",
      "22:32:58 | INFO    | [AAPL] p124: 10 items.\n",
      "22:33:00 | INFO    | [AAPL] p125: 10 items.\n",
      "22:33:02 | INFO    | [AAPL] p126: 10 items.\n",
      "22:33:04 | INFO    | [AAPL] p127: 10 items.\n",
      "22:33:06 | INFO    | [AAPL] p128: 10 items.\n",
      "22:33:08 | INFO    | [AAPL] p129: 10 items.\n",
      "22:33:10 | INFO    | [AAPL] p130: 10 items.\n",
      "22:33:11 | WARNING | HTTP 503 em https://br.investing.com/equities/apple-computer-inc-news/131; retry em 1.7s\n",
      "22:33:14 | INFO    | [AAPL] p131: 10 items.\n",
      "22:33:16 | INFO    | [AAPL] p132: 10 items.\n",
      "22:33:18 | INFO    | [AAPL] p133: 10 items.\n",
      "22:33:20 | INFO    | [AAPL] p134: 10 items.\n",
      "22:33:22 | INFO    | [AAPL] p135: 10 items.\n",
      "22:33:24 | INFO    | [AAPL] p136: 10 items.\n",
      "22:33:26 | INFO    | [AAPL] p137: 10 items.\n",
      "22:33:28 | INFO    | [AAPL] p138: 10 items.\n",
      "22:33:30 | INFO    | [AAPL] p139: 10 items.\n",
      "22:33:31 | INFO    | [AAPL] p140: 10 items.\n",
      "22:33:33 | INFO    | [AAPL] p141: 10 items.\n",
      "22:33:35 | INFO    | [AAPL] p142: 10 items.\n",
      "22:33:37 | INFO    | [AAPL] p143: 10 items.\n",
      "22:33:39 | INFO    | [AAPL] p144: 10 items.\n",
      "22:33:40 | INFO    | [AAPL] p145: 10 items.\n",
      "22:33:42 | INFO    | [AAPL] p146: 10 items.\n",
      "22:33:44 | INFO    | [AAPL] p147: 10 items.\n",
      "22:33:46 | INFO    | [AAPL] p148: 10 items.\n",
      "22:33:48 | INFO    | [AAPL] p149: 10 items.\n",
      "22:33:50 | INFO    | [AAPL] p150: 10 items.\n",
      "22:33:51 | INFO    | [AAPL] p151: 10 items.\n",
      "22:33:54 | INFO    | [AAPL] p152: 10 items.\n",
      "22:33:56 | INFO    | [AAPL] p153: 10 items.\n",
      "22:33:58 | INFO    | [AAPL] p154: 10 items.\n",
      "22:34:00 | INFO    | [AAPL] p155: 10 items.\n",
      "22:34:02 | INFO    | [AAPL] p156: 10 items.\n",
      "22:34:03 | INFO    | [AAPL] p157: 10 items.\n",
      "22:34:05 | INFO    | [AAPL] p158: 10 items.\n",
      "22:34:07 | INFO    | [AAPL] p159: 10 items.\n",
      "22:34:09 | INFO    | [AAPL] p160: 10 items.\n",
      "22:34:12 | INFO    | [AAPL] p161: 10 items.\n",
      "22:34:14 | INFO    | [AAPL] p162: 10 items.\n",
      "22:34:16 | INFO    | [AAPL] p163: 10 items.\n",
      "22:34:19 | INFO    | [AAPL] p164: 10 items.\n",
      "22:34:21 | INFO    | [AAPL] p165: 10 items.\n",
      "22:34:23 | INFO    | [AAPL] p166: 10 items.\n",
      "22:34:24 | INFO    | [AAPL] p167: 10 items.\n",
      "22:34:26 | INFO    | [AAPL] p168: 10 items.\n",
      "22:34:28 | INFO    | [AAPL] p169: 10 items.\n",
      "22:34:30 | INFO    | [AAPL] p170: 10 items.\n",
      "22:34:32 | INFO    | [AAPL] p171: 10 items.\n",
      "22:34:34 | INFO    | [AAPL] p172: 10 items.\n",
      "22:34:36 | INFO    | [AAPL] p173: 10 items.\n",
      "22:34:38 | INFO    | [AAPL] p174: 10 items.\n",
      "22:34:41 | INFO    | [AAPL] p175: 10 items.\n",
      "22:34:42 | INFO    | [AAPL] p176: 10 items.\n",
      "22:34:45 | INFO    | [AAPL] p177: 10 items.\n",
      "22:34:46 | WARNING | HTTP 503 em https://br.investing.com/equities/apple-computer-inc-news/178; retry em 2.0s\n",
      "22:34:49 | INFO    | [AAPL] p178: 10 items.\n",
      "22:34:51 | INFO    | [AAPL] p179: 10 items.\n",
      "22:34:53 | INFO    | [AAPL] p180: 10 items.\n",
      "22:34:54 | INFO    | [AAPL] p181: 10 items.\n",
      "22:34:56 | INFO    | [AAPL] p182: 10 items.\n",
      "22:34:58 | INFO    | [AAPL] p183: 10 items.\n",
      "22:35:00 | INFO    | [AAPL] p184: 10 items.\n",
      "22:35:02 | INFO    | [AAPL] p185: 10 items.\n",
      "22:35:04 | INFO    | [AAPL] p186: 10 items.\n",
      "22:35:06 | INFO    | [AAPL] p187: 10 items.\n",
      "22:35:07 | INFO    | [AAPL] p188: 10 items.\n",
      "22:35:09 | INFO    | [AAPL] p189: 10 items.\n",
      "22:35:11 | INFO    | [AAPL] p190: 10 items.\n",
      "22:35:13 | INFO    | [AAPL] p191: 10 items.\n",
      "22:35:15 | INFO    | [AAPL] p192: 10 items.\n",
      "22:35:17 | INFO    | [AAPL] p193: 10 items.\n",
      "22:35:19 | INFO    | [AAPL] p194: 10 items.\n",
      "22:35:21 | INFO    | [AAPL] p195: 10 items.\n",
      "22:35:23 | INFO    | [AAPL] p196: 10 items.\n",
      "22:35:25 | INFO    | [AAPL] p197: 10 items.\n",
      "22:35:27 | INFO    | [AAPL] p198: 10 items.\n",
      "22:35:29 | INFO    | [AAPL] p199: 10 items.\n",
      "22:35:31 | INFO    | [AAPL] p200: 10 items.\n",
      "22:35:33 | INFO    | [AAPL] p201: 10 items.\n",
      "22:35:34 | INFO    | [AAPL] p202: 10 items.\n",
      "22:35:36 | INFO    | [AAPL] p203: 10 items.\n",
      "22:35:38 | INFO    | [AAPL] p204: 10 items.\n",
      "22:35:40 | INFO    | [AAPL] p205: 10 items.\n",
      "22:35:42 | INFO    | [AAPL] p206: 10 items.\n",
      "22:35:44 | INFO    | [AAPL] p207: 10 items.\n",
      "22:35:46 | INFO    | [AAPL] p208: 10 items.\n",
      "22:35:47 | INFO    | [AAPL] p209: 10 items.\n",
      "22:35:49 | INFO    | [AAPL] p210: 10 items.\n",
      "22:35:51 | INFO    | [AAPL] p211: 10 items.\n",
      "22:35:53 | INFO    | [AAPL] p212: 10 items.\n",
      "22:35:55 | INFO    | [AAPL] p213: 10 items.\n",
      "22:35:56 | INFO    | [AAPL] p214: 9 items.\n",
      "22:35:58 | INFO    | [AAPL] p215: 10 items.\n",
      "22:36:00 | INFO    | [AAPL] p216: 10 items.\n",
      "22:36:02 | INFO    | [AAPL] p217: 10 items.\n",
      "22:36:04 | INFO    | [AAPL] p218: 10 items.\n",
      "22:36:05 | INFO    | [AAPL] p219: 10 items.\n",
      "22:36:09 | INFO    | [AAPL] p220: 10 items.\n",
      "22:36:11 | INFO    | [AAPL] p221: 10 items.\n",
      "22:36:13 | INFO    | [AAPL] p222: 10 items.\n",
      "22:36:15 | INFO    | [AAPL] p223: 10 items.\n",
      "22:36:17 | INFO    | [AAPL] p224: 10 items.\n",
      "22:36:19 | INFO    | [AAPL] p225: 10 items.\n",
      "22:36:21 | INFO    | [AAPL] p226: 10 items.\n",
      "22:36:23 | INFO    | [AAPL] p227: 10 items.\n",
      "22:36:24 | INFO    | [AAPL] p228: 10 items.\n",
      "22:36:26 | INFO    | [AAPL] p229: 10 items.\n",
      "22:36:28 | INFO    | [AAPL] p230: 10 items.\n",
      "22:36:30 | INFO    | [AAPL] p231: 10 items.\n",
      "22:36:32 | INFO    | [AAPL] p232: 10 items.\n",
      "22:36:34 | INFO    | [AAPL] p233: 10 items.\n",
      "22:36:36 | INFO    | [AAPL] p234: 10 items.\n",
      "22:36:38 | INFO    | [AAPL] p235: 10 items.\n",
      "22:36:39 | INFO    | [AAPL] p236: 10 items.\n",
      "22:36:41 | INFO    | [AAPL] p237: 10 items.\n",
      "22:36:43 | INFO    | [AAPL] p238: 10 items.\n",
      "22:36:45 | INFO    | [AAPL] p239: 10 items.\n",
      "22:36:47 | INFO    | [AAPL] p240: 10 items.\n",
      "22:36:48 | INFO    | [AAPL] p241: 10 items.\n",
      "22:36:50 | INFO    | [AAPL] p242: 10 items.\n",
      "22:36:52 | INFO    | [AAPL] p243: 10 items.\n",
      "22:36:54 | INFO    | [AAPL] p244: 10 items.\n",
      "22:36:56 | INFO    | [AAPL] p245: 10 items.\n",
      "22:36:58 | INFO    | [AAPL] p246: 10 items.\n",
      "22:36:59 | INFO    | [AAPL] p247: 10 items.\n",
      "22:37:01 | INFO    | [AAPL] p248: 10 items.\n",
      "22:37:03 | INFO    | [AAPL] p249: 10 items.\n",
      "22:37:06 | INFO    | [AAPL] p250: 10 items.\n",
      "22:37:08 | INFO    | [AAPL] p251: 10 items.\n",
      "22:37:10 | INFO    | [AAPL] p252: 10 items.\n",
      "22:37:11 | INFO    | [AAPL] p253: 10 items.\n",
      "22:37:13 | INFO    | [AAPL] p254: 10 items.\n",
      "22:37:15 | INFO    | [AAPL] p255: 10 items.\n",
      "22:37:17 | INFO    | [AAPL] p256: 10 items.\n",
      "22:37:19 | INFO    | [AAPL] p257: 10 items.\n",
      "22:37:21 | INFO    | [AAPL] p258: 10 items.\n",
      "22:37:23 | INFO    | [AAPL] p259: 10 items.\n",
      "22:37:25 | INFO    | [AAPL] p260: 10 items.\n",
      "22:37:27 | INFO    | [AAPL] p261: 10 items.\n",
      "22:37:29 | INFO    | [AAPL] p262: 10 items.\n",
      "22:37:31 | INFO    | [AAPL] p263: 10 items.\n",
      "22:37:33 | INFO    | [AAPL] p264: 10 items.\n",
      "22:37:34 | INFO    | [AAPL] p265: 10 items.\n",
      "22:37:36 | INFO    | [AAPL] p266: 10 items.\n",
      "22:37:38 | INFO    | [AAPL] p267: 10 items.\n",
      "22:37:40 | INFO    | [AAPL] p268: 10 items.\n",
      "22:37:42 | INFO    | [AAPL] p269: 10 items.\n",
      "22:37:44 | INFO    | [AAPL] p270: 10 items.\n",
      "22:37:46 | INFO    | [AAPL] p271: 10 items.\n",
      "22:37:48 | INFO    | [AAPL] p272: 10 items.\n",
      "22:37:50 | INFO    | [AAPL] p273: 10 items.\n",
      "22:37:52 | INFO    | [AAPL] p274: 10 items.\n",
      "22:37:54 | INFO    | [AAPL] p275: 10 items.\n",
      "22:37:56 | INFO    | [AAPL] p276: 10 items.\n",
      "22:37:58 | INFO    | [AAPL] p277: 10 items.\n",
      "22:38:00 | INFO    | [AAPL] p278: 10 items.\n",
      "22:38:01 | INFO    | [AAPL] p279: 10 items.\n",
      "22:38:03 | INFO    | [AAPL] p280: 10 items.\n",
      "22:38:05 | INFO    | [AAPL] p281: 10 items.\n",
      "22:38:07 | INFO    | [AAPL] p282: 10 items.\n",
      "22:38:10 | INFO    | [AAPL] p283: 10 items.\n",
      "22:38:12 | INFO    | [AAPL] p284: 10 items.\n",
      "22:38:14 | INFO    | [AAPL] p285: 10 items.\n",
      "22:38:16 | INFO    | [AAPL] p286: 10 items.\n",
      "22:38:18 | INFO    | [AAPL] p287: 10 items.\n",
      "22:38:20 | INFO    | [AAPL] p288: 10 items.\n",
      "22:38:22 | INFO    | [AAPL] p289: 10 items.\n",
      "22:38:24 | INFO    | [AAPL] p290: 10 items.\n",
      "22:38:26 | INFO    | [AAPL] p291: 7 items.\n",
      "22:38:28 | INFO    | [AAPL] p292: 10 items.\n",
      "22:38:30 | INFO    | [AAPL] p293: 10 items.\n",
      "22:38:31 | INFO    | [AAPL] p294: 10 items.\n",
      "22:38:33 | INFO    | [AAPL] p295: 10 items.\n",
      "22:38:35 | INFO    | [AAPL] p296: 10 items.\n",
      "22:38:37 | INFO    | [AAPL] p297: 9 items.\n",
      "22:38:39 | INFO    | [AAPL] p298: 10 items.\n",
      "22:38:40 | INFO    | [AAPL] p299: 10 items.\n",
      "22:38:42 | INFO    | [AAPL] p300: 10 items.\n",
      "22:38:44 | INFO    | [AAPL] p301: 10 items.\n",
      "22:38:46 | INFO    | [AAPL] p302: 10 items.\n",
      "22:38:48 | INFO    | [AAPL] p303: 10 items.\n",
      "22:38:49 | INFO    | [AAPL] p304: 10 items.\n",
      "22:38:51 | INFO    | [AAPL] p305: 10 items.\n",
      "22:38:53 | INFO    | [AAPL] p306: 10 items.\n",
      "22:38:55 | INFO    | [AAPL] p307: 10 items.\n",
      "22:38:58 | INFO    | [AAPL] p308: 10 items.\n",
      "22:39:00 | INFO    | [AAPL] p309: 10 items.\n",
      "22:39:02 | INFO    | [AAPL] p310: 10 items.\n",
      "22:39:04 | INFO    | [AAPL] p311: 10 items.\n",
      "22:39:06 | INFO    | [AAPL] p312: 10 items.\n",
      "22:39:10 | INFO    | [AAPL] p313: 10 items.\n",
      "22:39:12 | INFO    | [AAPL] p314: 10 items.\n",
      "22:39:14 | INFO    | [AAPL] p315: 10 items.\n",
      "22:39:16 | INFO    | [AAPL] p316: 10 items.\n",
      "22:39:18 | INFO    | [AAPL] p317: 10 items.\n",
      "22:39:20 | INFO    | [AAPL] p318: 10 items.\n",
      "22:39:22 | INFO    | [AAPL] p319: 10 items.\n",
      "22:39:23 | INFO    | [AAPL] p320: 10 items.\n",
      "22:39:25 | INFO    | [AAPL] p321: 10 items.\n",
      "22:39:27 | INFO    | [AAPL] p322: 10 items.\n",
      "22:39:29 | INFO    | [AAPL] p323: 10 items.\n",
      "22:39:31 | INFO    | [AAPL] p324: 10 items.\n",
      "22:39:33 | INFO    | [AAPL] p325: 10 items.\n",
      "22:39:35 | INFO    | [AAPL] p326: 10 items.\n",
      "22:39:37 | INFO    | [AAPL] p327: 10 items.\n",
      "22:39:39 | INFO    | [AAPL] p328: 10 items.\n",
      "22:39:41 | INFO    | [AAPL] p329: 10 items.\n",
      "22:39:42 | INFO    | [AAPL] p330: 10 items.\n",
      "22:39:44 | INFO    | [AAPL] p331: 10 items.\n",
      "22:39:46 | INFO    | [AAPL] p332: 10 items.\n",
      "22:39:48 | INFO    | [AAPL] p333: 10 items.\n",
      "22:39:50 | INFO    | [AAPL] p334: 10 items.\n",
      "22:39:53 | INFO    | [AAPL] p335: 10 items.\n",
      "22:39:55 | INFO    | [AAPL] p336: 10 items.\n",
      "22:39:57 | INFO    | [AAPL] p337: 10 items.\n",
      "22:39:59 | INFO    | [AAPL] p338: 10 items.\n",
      "22:40:01 | INFO    | [AAPL] p339: 10 items.\n",
      "22:40:02 | INFO    | [AAPL] p340: 10 items.\n",
      "22:40:04 | INFO    | [AAPL] p341: 10 items.\n",
      "22:40:06 | INFO    | [AAPL] p342: 10 items.\n",
      "22:40:08 | INFO    | [AAPL] p343: 10 items.\n",
      "22:40:10 | INFO    | [AAPL] p344: 10 items.\n",
      "22:40:12 | INFO    | [AAPL] p345: 10 items.\n",
      "22:40:14 | INFO    | [AAPL] p346: 10 items.\n",
      "22:40:16 | INFO    | [AAPL] p347: 10 items.\n",
      "22:40:18 | INFO    | [AAPL] p348: 10 items.\n",
      "22:40:19 | INFO    | [AAPL] p349: 10 items.\n",
      "22:40:21 | INFO    | [AAPL] p350: 10 items.\n",
      "22:40:23 | INFO    | [AAPL] p351: 10 items.\n",
      "22:40:25 | INFO    | [AAPL] p352: 10 items.\n",
      "22:40:27 | INFO    | [AAPL] p353: 10 items.\n",
      "22:40:29 | INFO    | [AAPL] p354: 10 items.\n",
      "22:40:31 | INFO    | [AAPL] p355: 10 items.\n",
      "22:40:32 | INFO    | [AAPL] p356: 10 items.\n",
      "22:40:34 | INFO    | [AAPL] p357: 10 items.\n",
      "22:40:36 | INFO    | [AAPL] p358: 10 items.\n",
      "22:40:38 | INFO    | [AAPL] p359: 10 items.\n",
      "22:40:40 | INFO    | [AAPL] p360: 10 items.\n",
      "22:40:42 | INFO    | [AAPL] p361: 10 items.\n",
      "22:40:44 | INFO    | [AAPL] p362: 10 items.\n",
      "22:40:45 | INFO    | [AAPL] p363: 10 items.\n",
      "22:40:48 | INFO    | [AAPL] p364: 10 items.\n",
      "22:40:49 | INFO    | [AAPL] p365: 10 items.\n",
      "22:40:51 | INFO    | [AAPL] p366: 10 items.\n",
      "22:40:53 | INFO    | [AAPL] p367: 10 items.\n",
      "22:40:55 | INFO    | [AAPL] p368: 10 items.\n",
      "22:40:57 | INFO    | [AAPL] p369: 10 items.\n",
      "22:40:58 | INFO    | [AAPL] p370: 10 items.\n",
      "22:41:00 | INFO    | [AAPL] p371: 10 items.\n",
      "22:41:02 | INFO    | [AAPL] p372: 10 items.\n",
      "22:41:04 | INFO    | [AAPL] p373: 10 items.\n",
      "22:41:06 | INFO    | [AAPL] p374: 10 items.\n",
      "22:41:08 | INFO    | [AAPL] p375: 10 items.\n",
      "22:41:10 | INFO    | [AAPL] p376: 10 items.\n",
      "22:41:12 | INFO    | [AAPL] p377: 10 items.\n",
      "22:41:13 | INFO    | [AAPL] p378: 10 items.\n",
      "22:41:15 | INFO    | [AAPL] p379: 10 items.\n",
      "22:41:17 | INFO    | [AAPL] p380: 10 items.\n",
      "22:41:20 | INFO    | [AAPL] p381: 10 items.\n",
      "22:41:22 | INFO    | [AAPL] p382: 10 items.\n",
      "22:41:24 | INFO    | [AAPL] p383: 10 items.\n",
      "22:41:25 | INFO    | [AAPL] p384: 10 items.\n",
      "22:41:27 | INFO    | [AAPL] p385: 10 items.\n",
      "22:41:29 | INFO    | [AAPL] p386: 10 items.\n",
      "22:41:31 | INFO    | [AAPL] p387: 10 items.\n",
      "22:41:32 | INFO    | [AAPL] p388: 10 items.\n",
      "22:41:34 | INFO    | [AAPL] p389: 9 items.\n",
      "22:41:36 | INFO    | [AAPL] p390: 10 items.\n",
      "22:41:38 | INFO    | [AAPL] p391: 10 items.\n",
      "22:41:40 | INFO    | [AAPL] p392: 10 items.\n",
      "22:41:42 | INFO    | [AAPL] p393: 10 items.\n",
      "22:41:43 | INFO    | [AAPL] p394: 10 items.\n",
      "22:41:45 | INFO    | [AAPL] p395: 8 items.\n",
      "22:41:47 | INFO    | [AAPL] p396: 10 items.\n",
      "22:41:49 | INFO    | [AAPL] p397: 10 items.\n",
      "22:41:51 | INFO    | [AAPL] p398: 10 items.\n",
      "22:41:53 | INFO    | [AAPL] p399: 7 items.\n",
      "22:41:55 | INFO    | [AAPL] p400: 10 items.\n",
      "22:41:57 | INFO    | [AAPL] p401: 10 items.\n",
      "22:41:58 | INFO    | [AAPL] p402: 10 items.\n",
      "22:42:00 | INFO    | [AAPL] p403: 10 items.\n",
      "22:42:02 | INFO    | [AAPL] p404: 10 items.\n",
      "22:42:04 | INFO    | [AAPL] p405: 10 items.\n",
      "22:42:05 | INFO    | [AAPL] p406: 10 items.\n",
      "22:42:07 | INFO    | [AAPL] p407: 10 items.\n",
      "22:42:09 | INFO    | [AAPL] p408: 10 items.\n",
      "22:42:11 | INFO    | [AAPL] p409: 10 items.\n",
      "22:42:13 | INFO    | [AAPL] p410: 10 items.\n",
      "22:42:15 | INFO    | [AAPL] p411: 10 items.\n",
      "22:42:17 | INFO    | [AAPL] p412: 10 items.\n",
      "22:42:19 | INFO    | [AAPL] p413: 10 items.\n",
      "22:42:21 | INFO    | [AAPL] p414: 10 items.\n",
      "22:42:23 | INFO    | [AAPL] p415: 10 items.\n",
      "22:42:25 | INFO    | [AAPL] p416: 10 items.\n",
      "22:42:27 | INFO    | [AAPL] p417: 10 items.\n",
      "22:42:28 | INFO    | [AAPL] p418: 10 items.\n",
      "22:42:30 | INFO    | [AAPL] p419: 10 items.\n",
      "22:42:32 | INFO    | [AAPL] p420: 10 items.\n",
      "22:42:34 | INFO    | [AAPL] p421: 10 items.\n",
      "22:42:36 | INFO    | [AAPL] p422: 10 items.\n",
      "22:42:38 | INFO    | [AAPL] p423: 10 items.\n",
      "22:42:40 | INFO    | [AAPL] p424: 10 items.\n",
      "22:42:42 | INFO    | [AAPL] p425: 10 items.\n",
      "22:42:44 | INFO    | [AAPL] p426: 10 items.\n",
      "22:42:47 | INFO    | [AAPL] p427: 10 items.\n",
      "22:42:49 | INFO    | [AAPL] p428: 10 items.\n",
      "22:42:51 | INFO    | [AAPL] p429: 10 items.\n",
      "22:42:53 | INFO    | [AAPL] p430: 10 items.\n",
      "22:42:55 | INFO    | [AAPL] p431: 10 items.\n",
      "22:42:56 | INFO    | [AAPL] p432: 10 items.\n",
      "22:42:59 | INFO    | [AAPL] p433: 10 items.\n",
      "22:43:01 | INFO    | [AAPL] p434: 10 items.\n",
      "22:43:02 | INFO    | [AAPL] p435: 10 items.\n",
      "22:43:04 | INFO    | [AAPL] p436: 10 items.\n",
      "22:43:06 | INFO    | [AAPL] p437: 10 items.\n",
      "22:43:11 | INFO    | [AAPL] p438: 10 items.\n",
      "22:43:14 | INFO    | [AAPL] p439: 10 items.\n",
      "22:43:15 | INFO    | [AAPL] p440: 10 items.\n",
      "22:43:17 | INFO    | [AAPL] p441: 10 items.\n",
      "22:43:19 | INFO    | [AAPL] p442: 10 items.\n",
      "22:43:21 | INFO    | [AAPL] p443: 10 items.\n",
      "22:43:23 | INFO    | [AAPL] p444: 10 items.\n",
      "22:43:25 | INFO    | [AAPL] p445: 10 items.\n",
      "22:43:27 | INFO    | [AAPL] p446: 10 items.\n",
      "22:43:29 | INFO    | [AAPL] p447: 10 items.\n",
      "22:43:31 | INFO    | [AAPL] p448: 10 items.\n",
      "22:43:33 | INFO    | [AAPL] p449: 9 items.\n",
      "22:43:34 | INFO    | [AAPL] p450: 10 items.\n",
      "22:43:36 | INFO    | [AAPL] p451: 10 items.\n",
      "22:43:38 | INFO    | [AAPL] p452: 10 items.\n",
      "22:43:40 | INFO    | [AAPL] p453: 10 items.\n",
      "22:43:42 | INFO    | [AAPL] p454: 10 items.\n",
      "22:43:44 | INFO    | [AAPL] p455: 10 items.\n",
      "22:43:45 | INFO    | [AAPL] p456: 10 items.\n",
      "22:43:48 | INFO    | [AAPL] p457: 10 items.\n",
      "22:43:49 | INFO    | [AAPL] p458: 10 items.\n",
      "22:43:51 | INFO    | [AAPL] p459: 10 items.\n",
      "22:43:53 | INFO    | [AAPL] p460: 10 items.\n",
      "22:43:55 | INFO    | [AAPL] p461: 10 items.\n",
      "22:43:57 | INFO    | [AAPL] p462: 10 items.\n",
      "22:43:59 | INFO    | [AAPL] p463: 4 items.\n",
      "22:44:01 | INFO    | [AAPL] p464: 10 items.\n",
      "22:44:03 | INFO    | [AAPL] p465: 10 items.\n",
      "22:44:05 | INFO    | [AAPL] p466: 10 items.\n",
      "22:44:07 | INFO    | [AAPL] p467: 10 items.\n",
      "22:44:11 | INFO    | [AAPL] p468: 10 items.\n",
      "22:44:13 | INFO    | [AAPL] p469: 10 items.\n",
      "22:44:15 | INFO    | [AAPL] p470: 10 items.\n",
      "22:44:16 | INFO    | [AAPL] p471: 10 items.\n",
      "22:44:19 | INFO    | [AAPL] p472: 10 items.\n",
      "22:44:20 | INFO    | [AAPL] p473: 10 items.\n",
      "22:44:22 | INFO    | [AAPL] p474: 10 items.\n",
      "22:44:24 | INFO    | [AAPL] p475: 10 items.\n",
      "22:44:26 | INFO    | [AAPL] p476: 10 items.\n",
      "22:44:28 | INFO    | [AAPL] p477: 10 items.\n",
      "22:44:30 | INFO    | [AAPL] p478: 10 items.\n",
      "22:44:31 | INFO    | [AAPL] p479: 10 items.\n",
      "22:44:33 | INFO    | [AAPL] p480: 10 items.\n",
      "22:44:35 | INFO    | [AAPL] p481: 10 items.\n",
      "22:44:37 | INFO    | [AAPL] p482: 10 items.\n",
      "22:44:39 | INFO    | [AAPL] p483: 10 items.\n",
      "22:44:41 | INFO    | [AAPL] p484: 10 items.\n",
      "22:44:45 | INFO    | [AAPL] p485: 10 items.\n",
      "22:44:47 | INFO    | [AAPL] p486: 10 items.\n",
      "22:44:50 | INFO    | [AAPL] p487: 10 items.\n",
      "22:44:52 | INFO    | [AAPL] p488: 10 items.\n",
      "22:44:54 | INFO    | [AAPL] p489: 10 items.\n",
      "22:44:56 | INFO    | [AAPL] p490: 10 items.\n",
      "22:44:58 | INFO    | [AAPL] p491: 10 items.\n",
      "22:45:00 | INFO    | [AAPL] p492: 10 items.\n",
      "22:45:02 | INFO    | [AAPL] p493: 10 items.\n",
      "22:45:03 | INFO    | [AAPL] p494: 5 items.\n",
      "22:45:05 | INFO    | [AAPL] p495: 10 items.\n",
      "22:45:07 | INFO    | [AAPL] p496: 10 items.\n",
      "22:45:09 | INFO    | [AAPL] p497: 10 items.\n",
      "22:45:11 | INFO    | [AAPL] p498: 10 items.\n",
      "22:45:12 | INFO    | [AAPL] p499: 10 items.\n",
      "22:45:14 | INFO    | [AAPL] p500: 10 items.\n",
      "22:45:17 | INFO    | [AAPL] p501: 10 items.\n",
      "22:45:19 | INFO    | [AAPL] p502: 10 items.\n",
      "22:45:22 | INFO    | [AAPL] p503: 10 items.\n",
      "22:45:24 | INFO    | [AAPL] p504: 10 items.\n",
      "22:45:26 | INFO    | [AAPL] p505: 10 items.\n",
      "22:45:28 | INFO    | [AAPL] p506: 10 items.\n",
      "22:45:30 | INFO    | [AAPL] p507: 10 items.\n",
      "22:45:32 | INFO    | [AAPL] p508: 10 items.\n",
      "22:45:34 | INFO    | [AAPL] p509: 10 items.\n",
      "22:45:36 | INFO    | [AAPL] p510: 10 items.\n",
      "22:45:38 | INFO    | [AAPL] p511: 10 items.\n",
      "22:45:40 | INFO    | [AAPL] p512: 10 items.\n",
      "22:45:42 | INFO    | [AAPL] p513: 10 items.\n",
      "22:45:43 | INFO    | [AAPL] p514: 10 items.\n",
      "22:45:45 | INFO    | [AAPL] p515: 10 items.\n",
      "22:45:47 | INFO    | [AAPL] p516: 10 items.\n",
      "22:45:50 | INFO    | [AAPL] p517: 10 items.\n",
      "22:45:51 | INFO    | [AAPL] p518: 10 items.\n",
      "22:45:54 | INFO    | [AAPL] p519: 10 items.\n",
      "22:45:59 | INFO    | [AAPL] p520: 10 items.\n",
      "22:46:01 | INFO    | [AAPL] p521: 10 items.\n",
      "22:46:03 | INFO    | [AAPL] p522: 10 items.\n",
      "22:46:05 | INFO    | [AAPL] p523: 10 items.\n",
      "22:46:07 | INFO    | [AAPL] p524: 10 items.\n",
      "22:46:09 | INFO    | [AAPL] p525: 10 items.\n",
      "22:46:10 | INFO    | [AAPL] p526: 10 items.\n",
      "22:46:12 | INFO    | [AAPL] p527: 10 items.\n",
      "22:46:14 | INFO    | [AAPL] p528: 10 items.\n",
      "22:46:17 | INFO    | [AAPL] p529: 10 items.\n",
      "22:46:19 | INFO    | [AAPL] p530: 10 items.\n",
      "22:46:22 | INFO    | [AAPL] p531: 10 items.\n",
      "22:46:24 | INFO    | [AAPL] p532: 10 items.\n",
      "22:46:26 | INFO    | [AAPL] p533: 10 items.\n",
      "22:46:27 | INFO    | [AAPL] p534: 10 items.\n",
      "22:46:31 | INFO    | [AAPL] p535: 10 items.\n",
      "22:46:33 | INFO    | [AAPL] p536: 10 items.\n",
      "22:46:35 | INFO    | [AAPL] p537: 10 items.\n",
      "22:46:36 | INFO    | [AAPL] p538: 10 items.\n",
      "22:46:38 | INFO    | [AAPL] p539: 10 items.\n",
      "22:46:40 | INFO    | [AAPL] p540: 10 items.\n",
      "22:46:42 | INFO    | [AAPL] p541: 10 items.\n",
      "22:46:44 | INFO    | [AAPL] p542: 10 items.\n",
      "22:46:45 | INFO    | [AAPL] p543: 10 items.\n",
      "22:46:47 | INFO    | [AAPL] p544: 10 items.\n",
      "22:46:49 | INFO    | [AAPL] p545: 10 items.\n",
      "22:46:52 | INFO    | [AAPL] p546: 10 items.\n",
      "22:46:54 | INFO    | [AAPL] p547: 10 items.\n",
      "22:46:56 | INFO    | [AAPL] p548: 10 items.\n",
      "22:46:58 | INFO    | [AAPL] p549: 10 items.\n",
      "22:47:00 | INFO    | [AAPL] p550: 10 items.\n",
      "22:47:02 | INFO    | [AAPL] p551: 10 items.\n",
      "22:47:04 | INFO    | [AAPL] p552: 10 items.\n",
      "22:47:05 | INFO    | [AAPL] p553: 10 items.\n",
      "22:47:07 | INFO    | [AAPL] p554: 10 items.\n",
      "22:47:09 | INFO    | [AAPL] p555: 10 items.\n",
      "22:47:11 | INFO    | [AAPL] p556: 10 items.\n",
      "22:47:13 | INFO    | [AAPL] p557: 10 items.\n",
      "22:47:15 | INFO    | [AAPL] p558: 10 items.\n",
      "22:47:17 | INFO    | [AAPL] p559: 10 items.\n",
      "22:47:19 | INFO    | [AAPL] p560: 10 items.\n",
      "22:47:21 | INFO    | [AAPL] p561: 10 items.\n",
      "22:47:23 | INFO    | [AAPL] p562: 10 items.\n",
      "22:47:25 | INFO    | [AAPL] p563: 10 items.\n",
      "22:47:27 | INFO    | [AAPL] p564: 10 items.\n",
      "22:47:28 | INFO    | [AAPL] p565: 10 items.\n",
      "22:47:30 | INFO    | [AAPL] p566: 10 items.\n",
      "22:47:32 | INFO    | [AAPL] p567: 10 items.\n",
      "22:47:34 | INFO    | [AAPL] p568: 10 items.\n",
      "22:47:35 | INFO    | [AAPL] p569: 10 items.\n",
      "22:47:37 | INFO    | [AAPL] p570: 10 items.\n",
      "22:47:39 | INFO    | [AAPL] p571: 10 items.\n",
      "22:47:41 | INFO    | [AAPL] p572: 10 items.\n",
      "22:47:43 | INFO    | [AAPL] p573: 10 items.\n",
      "22:47:45 | INFO    | [AAPL] p574: 10 items.\n",
      "22:47:46 | INFO    | [AAPL] p575: 10 items.\n",
      "22:47:48 | INFO    | [AAPL] p576: 10 items.\n",
      "22:47:50 | INFO    | [AAPL] p577: 10 items.\n",
      "22:47:52 | INFO    | [AAPL] p578: 10 items.\n",
      "22:47:54 | INFO    | [AAPL] p579: 10 items.\n",
      "22:47:56 | INFO    | [AAPL] p580: 10 items.\n",
      "22:47:59 | INFO    | [AAPL] p581: 10 items.\n",
      "22:48:01 | INFO    | [AAPL] p582: 10 items.\n",
      "22:48:04 | INFO    | [AAPL] p583: 10 items.\n",
      "22:48:06 | INFO    | [AAPL] p584: 10 items.\n",
      "22:48:07 | INFO    | [AAPL] p585: 10 items.\n",
      "22:48:09 | INFO    | [AAPL] p586: 10 items.\n",
      "22:48:11 | INFO    | [AAPL] p587: 10 items.\n",
      "22:48:13 | INFO    | [AAPL] p588: 10 items.\n",
      "22:48:15 | INFO    | [AAPL] p589: 10 items.\n",
      "22:48:17 | INFO    | [AAPL] p590: 10 items.\n",
      "22:48:19 | INFO    | [AAPL] p591: 10 items.\n",
      "22:48:21 | INFO    | [AAPL] p592: 10 items.\n",
      "22:48:23 | INFO    | [AAPL] p593: 10 items.\n",
      "22:48:25 | INFO    | [AAPL] p594: 10 items.\n",
      "22:48:26 | INFO    | [AAPL] p595: 10 items.\n",
      "22:48:29 | INFO    | [AAPL] p596: 10 items.\n",
      "22:48:31 | INFO    | [AAPL] p597: 10 items.\n",
      "22:48:32 | INFO    | [AAPL] p598: 10 items.\n",
      "22:48:35 | INFO    | [AAPL] p599: 10 items.\n",
      "22:48:37 | INFO    | [AAPL] p600: 10 items.\n",
      "22:48:39 | INFO    | [AAPL] p601: 10 items.\n",
      "22:48:40 | INFO    | [AAPL] p602: 10 items.\n",
      "22:48:42 | INFO    | [AAPL] p603: 10 items.\n",
      "22:48:44 | INFO    | [AAPL] p604: 10 items.\n",
      "22:48:46 | INFO    | [AAPL] p605: 10 items.\n",
      "22:48:48 | INFO    | [AAPL] p606: 10 items.\n",
      "22:48:50 | INFO    | [AAPL] p607: 10 items.\n",
      "22:48:52 | INFO    | [AAPL] p608: 10 items.\n",
      "22:48:53 | INFO    | [AAPL] p609: 10 items.\n",
      "22:48:55 | INFO    | [AAPL] p610: 10 items.\n",
      "22:48:57 | INFO    | [AAPL] p611: 10 items.\n",
      "22:48:59 | INFO    | [AAPL] p612: 10 items.\n",
      "22:49:01 | INFO    | [AAPL] p613: 10 items.\n",
      "22:49:02 | INFO    | [AAPL] p614: 10 items.\n",
      "22:49:04 | INFO    | [AAPL] p615: 10 items.\n",
      "22:49:08 | INFO    | [AAPL] p616: 10 items.\n",
      "22:49:09 | INFO    | [AAPL] p617: 10 items.\n",
      "22:49:11 | INFO    | [AAPL] p618: 10 items.\n",
      "22:49:13 | INFO    | [AAPL] p619: 10 items.\n",
      "22:49:15 | INFO    | [AAPL] p620: 10 items.\n",
      "22:49:17 | INFO    | [AAPL] p621: 10 items.\n",
      "22:49:19 | INFO    | [AAPL] p622: 10 items.\n",
      "22:49:21 | INFO    | [AAPL] p623: 10 items.\n",
      "22:49:23 | INFO    | [AAPL] p624: 10 items.\n",
      "22:49:24 | INFO    | [AAPL] p625: 10 items.\n",
      "22:49:26 | INFO    | [AAPL] p626: 10 items.\n",
      "22:49:28 | INFO    | [AAPL] p627: 10 items.\n",
      "22:49:30 | INFO    | [AAPL] p628: 10 items.\n",
      "22:49:33 | INFO    | [AAPL] p629: 10 items.\n",
      "22:49:35 | INFO    | [AAPL] p630: 10 items.\n",
      "22:49:37 | INFO    | [AAPL] p631: 10 items.\n",
      "22:49:39 | INFO    | [AAPL] p632: 10 items.\n",
      "22:49:40 | INFO    | [AAPL] p633: 10 items.\n",
      "22:49:42 | INFO    | [AAPL] p634: 10 items.\n",
      "22:49:44 | INFO    | [AAPL] p635: 10 items.\n",
      "22:49:46 | INFO    | [AAPL] p636: 10 items.\n",
      "22:49:48 | INFO    | [AAPL] p637: 10 items.\n",
      "22:49:50 | INFO    | [AAPL] p638: 10 items.\n",
      "22:49:52 | INFO    | [AAPL] p639: 10 items.\n",
      "22:49:54 | INFO    | [AAPL] p640: 10 items.\n",
      "22:49:56 | INFO    | [AAPL] p641: 10 items.\n",
      "22:49:57 | INFO    | [AAPL] p642: 10 items.\n",
      "22:49:59 | INFO    | [AAPL] p643: 10 items.\n",
      "22:50:01 | INFO    | [AAPL] p644: 10 items.\n",
      "22:50:03 | INFO    | [AAPL] p645: 10 items.\n",
      "22:50:05 | INFO    | [AAPL] p646: 10 items.\n",
      "22:50:07 | INFO    | [AAPL] p647: 10 items.\n",
      "22:50:09 | INFO    | [AAPL] p648: 10 items.\n",
      "22:50:11 | INFO    | [AAPL] p649: 10 items.\n",
      "22:50:13 | INFO    | [AAPL] p650: 10 items.\n",
      "22:50:15 | INFO    | [AAPL] p651: 10 items.\n",
      "22:50:17 | INFO    | [AAPL] p652: 10 items.\n",
      "22:50:19 | INFO    | [AAPL] p653: 10 items.\n",
      "22:50:21 | INFO    | [AAPL] p654: 10 items.\n",
      "22:50:22 | INFO    | [AAPL] p655: 10 items.\n",
      "22:50:24 | INFO    | [AAPL] p656: 10 items.\n",
      "22:50:27 | INFO    | [AAPL] p657: 10 items.\n",
      "22:50:29 | INFO    | [AAPL] p658: 10 items.\n",
      "22:50:31 | INFO    | [AAPL] p659: 10 items.\n",
      "22:50:32 | INFO    | [AAPL] p660: 10 items.\n",
      "22:50:34 | INFO    | [AAPL] p661: 10 items.\n",
      "22:50:36 | INFO    | [AAPL] p662: 10 items.\n",
      "22:50:38 | INFO    | [AAPL] p663: 10 items.\n",
      "22:50:40 | INFO    | [AAPL] p664: 10 items.\n",
      "22:50:42 | INFO    | [AAPL] p665: 10 items.\n",
      "22:50:43 | INFO    | [AAPL] p666: 10 items.\n",
      "22:50:45 | INFO    | [AAPL] p667: 10 items.\n",
      "22:50:47 | INFO    | [AAPL] p668: 10 items.\n",
      "22:50:49 | INFO    | [AAPL] p669: 10 items.\n",
      "22:50:50 | INFO    | [AAPL] p670: 10 items.\n",
      "22:50:52 | INFO    | [AAPL] p671: 10 items.\n",
      "22:50:54 | INFO    | [AAPL] p672: 10 items.\n",
      "22:50:56 | INFO    | [AAPL] p673: 10 items.\n",
      "22:50:58 | INFO    | [AAPL] p674: 10 items.\n",
      "22:50:59 | INFO    | [AAPL] p675: 10 items.\n",
      "22:51:01 | INFO    | [AAPL] p676: 10 items.\n",
      "22:51:03 | INFO    | [AAPL] p677: 10 items.\n",
      "22:51:05 | INFO    | [AAPL] p678: 10 items.\n",
      "22:51:07 | INFO    | [AAPL] p679: 10 items.\n",
      "22:51:08 | INFO    | [AAPL] p680: 10 items.\n",
      "22:51:11 | INFO    | [AAPL] p681: 10 items.\n",
      "22:51:13 | INFO    | [AAPL] p682: 10 items.\n",
      "22:51:15 | INFO    | [AAPL] p683: 10 items.\n",
      "22:51:17 | INFO    | [AAPL] p684: 10 items.\n",
      "22:51:19 | INFO    | [AAPL] p685: 10 items.\n",
      "22:51:21 | INFO    | [AAPL] p686: 10 items.\n",
      "22:51:23 | INFO    | [AAPL] p687: 10 items.\n",
      "22:51:25 | INFO    | [AAPL] p688: 10 items.\n",
      "22:51:26 | INFO    | [AAPL] p689: 10 items.\n",
      "22:51:28 | INFO    | [AAPL] p690: 10 items.\n",
      "22:51:30 | INFO    | [AAPL] p691: 10 items.\n",
      "22:51:32 | INFO    | [AAPL] p692: 10 items.\n",
      "22:51:34 | INFO    | [AAPL] p693: 10 items.\n",
      "22:51:36 | INFO    | [AAPL] p694: 10 items.\n",
      "22:51:38 | INFO    | [AAPL] p695: 10 items.\n",
      "22:51:40 | INFO    | [AAPL] p696: 10 items.\n",
      "22:51:42 | INFO    | [AAPL] p697: 10 items.\n",
      "22:51:44 | INFO    | [AAPL] p698: 10 items.\n",
      "22:51:46 | INFO    | [AAPL] p699: 10 items.\n",
      "22:51:48 | INFO    | [AAPL] p700: 10 items.\n",
      "22:51:49 | INFO    | [AAPL] p701: 10 items.\n",
      "22:51:51 | INFO    | [AAPL] p702: 10 items.\n",
      "22:51:53 | INFO    | [AAPL] p703: 10 items.\n",
      "22:51:55 | INFO    | [AAPL] p704: 10 items.\n",
      "22:51:57 | INFO    | [AAPL] p705: 10 items.\n",
      "22:51:58 | INFO    | [AAPL] p706: 10 items.\n",
      "22:52:00 | INFO    | [AAPL] p707: 10 items.\n",
      "22:52:02 | INFO    | [AAPL] p708: 10 items.\n",
      "22:52:04 | INFO    | [AAPL] p709: 10 items.\n",
      "22:52:06 | INFO    | [AAPL] p710: 10 items.\n",
      "22:52:08 | INFO    | [AAPL] p711: 10 items.\n",
      "22:52:10 | INFO    | [AAPL] p712: 10 items.\n",
      "22:52:11 | INFO    | [AAPL] p713: 10 items.\n",
      "22:52:13 | INFO    | [AAPL] p714: 10 items.\n",
      "22:52:15 | INFO    | [AAPL] p715: 10 items.\n",
      "22:52:17 | INFO    | [AAPL] p716: 10 items.\n",
      "22:52:19 | INFO    | [AAPL] p717: 10 items.\n",
      "22:52:21 | INFO    | [AAPL] p718: 10 items.\n",
      "22:52:22 | INFO    | [AAPL] p719: 10 items.\n",
      "22:52:24 | INFO    | [AAPL] p720: 10 items.\n",
      "22:52:26 | INFO    | [AAPL] p721: 10 items.\n",
      "22:52:28 | INFO    | [AAPL] p722: 10 items.\n",
      "22:52:29 | INFO    | [AAPL] p723: 10 items.\n",
      "22:52:32 | INFO    | [AAPL] p724: 10 items.\n",
      "22:52:34 | INFO    | [AAPL] p725: 10 items.\n",
      "22:52:39 | INFO    | [AAPL] p726: 10 items.\n",
      "22:52:41 | INFO    | [AAPL] p727: 10 items.\n",
      "22:52:42 | INFO    | [AAPL] p728: 10 items.\n",
      "22:52:44 | INFO    | [AAPL] p729: 10 items.\n",
      "22:52:46 | INFO    | [AAPL] p730: 10 items.\n",
      "22:52:48 | INFO    | [AAPL] p731: 10 items.\n",
      "22:52:50 | INFO    | [AAPL] p732: 10 items.\n",
      "22:52:52 | INFO    | [AAPL] p733: 10 items.\n",
      "22:52:54 | INFO    | [AAPL] p734: 10 items.\n",
      "22:52:56 | INFO    | [AAPL] p735: 10 items.\n",
      "22:52:58 | INFO    | [AAPL] p736: 10 items.\n",
      "22:53:01 | INFO    | [AAPL] p737: 10 items.\n",
      "22:53:02 | INFO    | [AAPL] p738: 10 items.\n",
      "22:53:04 | INFO    | [AAPL] p739: 10 items.\n",
      "22:53:06 | INFO    | [AAPL] p740: 10 items.\n",
      "22:53:08 | INFO    | [AAPL] p741: 10 items.\n",
      "22:53:10 | INFO    | [AAPL] p742: 10 items.\n",
      "22:53:12 | INFO    | [AAPL] p743: 10 items.\n",
      "22:53:14 | INFO    | [AAPL] p744: 10 items.\n",
      "22:53:15 | INFO    | [AAPL] p745: 10 items.\n",
      "22:53:17 | INFO    | [AAPL] p746: 10 items.\n",
      "22:53:19 | INFO    | [AAPL] p747: 10 items.\n",
      "22:53:21 | INFO    | [AAPL] p748: 10 items.\n",
      "22:53:23 | INFO    | [AAPL] p749: 10 items.\n",
      "22:53:24 | INFO    | [AAPL] p750: 10 items.\n",
      "22:53:26 | INFO    | [AAPL] p751: 10 items.\n",
      "22:53:28 | INFO    | [AAPL] p752: 10 items.\n",
      "22:53:30 | INFO    | [AAPL] p753: 10 items.\n",
      "22:53:32 | INFO    | [AAPL] p754: 10 items.\n",
      "22:53:33 | INFO    | [AAPL] p755: 10 items.\n",
      "22:53:35 | INFO    | [AAPL] p756: 10 items.\n",
      "22:53:37 | INFO    | [AAPL] p757: 10 items.\n",
      "22:53:39 | INFO    | [AAPL] p758: 10 items.\n",
      "22:53:41 | INFO    | [AAPL] p759: 10 items.\n",
      "22:53:43 | INFO    | [AAPL] p760: 10 items.\n",
      "22:53:45 | INFO    | [AAPL] p761: 10 items.\n",
      "22:53:47 | INFO    | [AAPL] p762: 10 items.\n",
      "22:53:49 | INFO    | [AAPL] p763: 10 items.\n",
      "22:53:50 | INFO    | [AAPL] p764: 10 items.\n",
      "22:53:52 | INFO    | [AAPL] p765: 10 items.\n",
      "22:53:54 | INFO    | [AAPL] p766: 10 items.\n",
      "22:53:56 | INFO    | [AAPL] p767: 10 items.\n",
      "22:53:57 | INFO    | [AAPL] p768: 10 items.\n",
      "22:53:59 | INFO    | [AAPL] p769: 10 items.\n",
      "22:54:01 | INFO    | [AAPL] p770: 10 items.\n",
      "22:54:03 | INFO    | [AAPL] p771: 10 items.\n",
      "22:54:05 | INFO    | [AAPL] p772: 10 items.\n",
      "22:54:07 | INFO    | [AAPL] p773: 10 items.\n",
      "22:54:09 | INFO    | [AAPL] p774: 10 items.\n",
      "22:54:10 | INFO    | [AAPL] p775: 10 items.\n",
      "22:54:12 | INFO    | [AAPL] p776: 10 items.\n",
      "22:54:14 | INFO    | [AAPL] p777: 10 items.\n",
      "22:54:17 | INFO    | [AAPL] p778: 7 items.\n",
      "22:54:20 | INFO    | [AAPL] p779: 0 items.\n",
      "22:54:21 | INFO    | [AAPL] p780: 0 items.\n",
      "Empresas:   2%|▏         | 1/43 [25:27<17:49:10, 1527.40s/it]22:54:21 | WARNING | [Microsoft] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Alphabet (Google)] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Amazon] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [NVIDIA] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Meta Platforms (Facebook)] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Tesla] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Berkshire Hathaway] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Eli Lilly] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Visa] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [JPMorgan Chase] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Exxon Mobil] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Johnson & Johnson] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Mastercard] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Procter & Gamble (P&G)] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Costco] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Bank of America] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Netflix] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [AMD] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Coca-Cola] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [PepsiCo] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Walmart] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [McDonald's] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Disney] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Caterpillar] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Intel] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Cisco Systems] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Oracle] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Salesforce] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Adobe] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Nike] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Starbucks] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Boeing] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Goldman Sachs] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Morgan Stanley] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Ford] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [General Motors] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Pfizer] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Chevron] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [PayPal] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Coinbase] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Uber] Link News vazio; pulando.\n",
      "22:54:21 | WARNING | [Airbnb] Link News vazio; pulando.\n",
      "Empresas: 100%|██████████| 43/43 [25:27<00:00, 35.52s/it]    \n",
      "22:54:22 | INFO    | Salvo 7,754 notícias em investing_news.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser as du\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# ---------------- Config & Globals ----------------\n",
    "SP_TZ = ZoneInfo(\"America/Sao_Paulo\")\n",
    "\n",
    "DEFAULT_EXCEL = \"../data/BaseRefAtivos.xlsx\"\n",
    "DEFAULT_OUT = \"../data/investing_news.parquet\"\n",
    "DEFAULT_MAX_PAGES = 780  # <- limite padrão para facilitar debug rápido\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/127.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}\n",
    "\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update(HEADERS)\n",
    "\n",
    "RELATIVE_REGEX = re.compile(\n",
    "    r\"(?P<num>\\d+)\\s*(?P<unit>min|mins|minutos|minuto|hora|horas|dia|dias)\\s*atr[aá]s\",\n",
    "    flags=re.IGNORECASE,\n",
    ")\n",
    "\n",
    "# ---------------- Logging ----------------\n",
    "def setup_logging(verbose: bool = False, debug: bool = False) -> None:\n",
    "    level = logging.INFO\n",
    "    if verbose or debug:\n",
    "        level = logging.DEBUG\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "        datefmt=\"%H:%M:%S\",\n",
    "    )\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# ---------------- Utils ----------------\n",
    "def normalize_news_url(url: str) -> str:\n",
    "    \"\"\"Garante base ...-news e remove sufixo /<n> para paginar manualmente.\"\"\"\n",
    "    url = (url or \"\").strip()\n",
    "    if not url:\n",
    "        return url\n",
    "    if url.endswith(\"-new\"):\n",
    "        url = url + \"s\"\n",
    "    url = re.sub(r\"/+$\", \"\", url)\n",
    "    m = re.search(r\"/(\\d+)$\", url)\n",
    "    if m:\n",
    "        url = url[: - (len(m.group(0)))]\n",
    "    return url\n",
    "\n",
    "def page_url(url_base: str, page: int) -> str:\n",
    "    return f\"{url_base}/{page}\"\n",
    "\n",
    "def parse_datetime_from_time_tag(time_tag) -> Optional[datetime]:\n",
    "    if time_tag is None:\n",
    "        return None\n",
    "\n",
    "    text = (time_tag.get_text() or \"\").strip().lower()\n",
    "    m = RELATIVE_REGEX.search(text)\n",
    "    if m:\n",
    "        num = int(m.group(\"num\"))\n",
    "        unit = m.group(\"unit\")\n",
    "        now_sp = datetime.now(SP_TZ)\n",
    "\n",
    "        if unit.startswith(\"min\"):\n",
    "            dt = now_sp - timedelta(minutes=num)\n",
    "        elif unit.startswith(\"hora\"):\n",
    "            dt = now_sp - timedelta(hours=num)\n",
    "        else:\n",
    "            dt = now_sp - timedelta(days=num)\n",
    "        return dt\n",
    "\n",
    "    dt_attr = time_tag.get(\"datetime\")\n",
    "    if dt_attr:\n",
    "        try:\n",
    "            dt = du.parse(dt_attr)\n",
    "            if dt.tzinfo is None:\n",
    "                dt = dt.replace(tzinfo=SP_TZ)\n",
    "            return dt.astimezone(SP_TZ)\n",
    "        except Exception as e:\n",
    "            log.debug(f\"Falha parse datetime attr '{dt_attr}': {e}\")\n",
    "\n",
    "    # fallback: parse do texto absoluto, ex.: \"12 de out. de 2025\"\n",
    "    try:\n",
    "        dt = du.parse(text, dayfirst=True, fuzzy=True, languages=[\"pt\"])\n",
    "        if dt is not None:\n",
    "            if dt.tzinfo is None:\n",
    "                dt = dt.replace(tzinfo=SP_TZ)\n",
    "            return dt.astimezone(SP_TZ)\n",
    "    except Exception as e:\n",
    "        log.debug(f\"Falha parse texto de data '{text}': {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def deduce_country_language_from_url(url: str) -> tuple[str, str]:\n",
    "    if \"br.investing.com\" in url:\n",
    "        return (\"BR\", \"pt-BR\")\n",
    "    return (\"\", \"\")\n",
    "\n",
    "def make_news_id(url: str, title: str) -> str:\n",
    "    base = (url or \"\").strip() + \"||\" + (title or \"\").strip()\n",
    "    return str(uuid.uuid5(uuid.NAMESPACE_URL, base))\n",
    "\n",
    "def html_debug_dump(html: str, company: str, page: int, outdir: Path) -> None:\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    fn = outdir / f\"{safe_filename(company)}_p{page:04d}.html\"\n",
    "    try:\n",
    "        fn.write_text(html, encoding=\"utf-8\")\n",
    "        log.debug(f\"HTML salvo para debug: {fn}\")\n",
    "    except Exception as e:\n",
    "        log.warning(f\"Falha ao salvar HTML de debug: {e}\")\n",
    "\n",
    "def safe_filename(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", s.strip())\n",
    "\n",
    "# ---------------- HTTP com backoff ----------------\n",
    "def fetch(url: str, max_retries: int = 5, timeout: int = 25) -> Optional[requests.Response]:\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            r = SESSION.get(url, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                return r\n",
    "            if r.status_code in (404, 410):\n",
    "                log.info(f\"HTTP {r.status_code} em {url} (provável fim).\")\n",
    "                return None\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                wait = (1.5 * (i + 1)) + random.random()\n",
    "                log.warning(f\"HTTP {r.status_code} em {url}; retry em {wait:.1f}s\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "            log.warning(f\"HTTP {r.status_code} em {url}; sem retry programado.\")\n",
    "            return None\n",
    "        except requests.RequestException as e:\n",
    "            wait = (1.2 * (i + 1)) + random.random()\n",
    "            log.warning(f\"Erro rede: {e}; retry em {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "    log.error(f\"Falhou após {max_retries} tentativas: {url}\")\n",
    "    return None\n",
    "\n",
    "# ---------------- Parsing ----------------\n",
    "def parse_news_items(html: str, ticker: str, sector: str) -> List[Dict]:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    ul = soup.find(\"ul\", attrs={\"data-test\": \"news-list\"})\n",
    "    if not ul:\n",
    "        log.debug(\"Ul[data-test='news-list'] não encontrada — página pode ter mudado.\")\n",
    "        return []\n",
    "\n",
    "    items: List[Dict] = []\n",
    "    arts = ul.select(\"article[data-test='article-item']\")\n",
    "    if not arts:\n",
    "        log.debug(\"Nenhum article[data-test='article-item'] encontrado nesta página.\")\n",
    "        return []\n",
    "\n",
    "    for art in arts:\n",
    "        a_title = art.select_one(\"a[data-test='article-title-link']\")\n",
    "        if not a_title:\n",
    "            log.debug(\"a[data-test='article-title-link'] ausente em um article; pulando.\")\n",
    "            continue\n",
    "\n",
    "        headline = (a_title.get_text() or \"\").strip()\n",
    "        url = a_title.get(\"href\") or \"\"\n",
    "        if url.startswith(\"/\"):\n",
    "            url = \"https://br.investing.com\" + url\n",
    "\n",
    "        a_provider = art.select_one(\"a[data-test='article-provider-link']\")\n",
    "        source = (a_provider.get_text().strip() if a_provider else \"\").strip()\n",
    "\n",
    "        t = art.select_one(\"time[data-test='article-publish-date']\")\n",
    "        dt = parse_datetime_from_time_tag(t)\n",
    "\n",
    "        country, language = deduce_country_language_from_url(url)\n",
    "        _id = make_news_id(url, headline)\n",
    "\n",
    "        items.append(\n",
    "            {\n",
    "                \"id\": _id,\n",
    "                \"datetime\": dt.isoformat() if dt else None,\n",
    "                \"source\": source,\n",
    "                \"headline\": headline,\n",
    "                \"ticker\": ticker,\n",
    "                \"sector\": sector,\n",
    "                \"country\": country,\n",
    "                \"url\": url,\n",
    "                \"language\": language,\n",
    "            }\n",
    "        )\n",
    "    return items\n",
    "\n",
    "def guess_last_page(html: str) -> Optional[int]:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    pag_links = soup.select(\"div.flex.items-center.gap-2 a\")\n",
    "    nums = []\n",
    "    for a in pag_links:\n",
    "        txt = (a.get_text() or \"\").strip()\n",
    "        if txt.isdigit():\n",
    "            nums.append(int(txt))\n",
    "    return max(nums) if nums else None\n",
    "\n",
    "# ---------------- Scraper por empresa ----------------\n",
    "def scrape_company(\n",
    "    link_news: str,\n",
    "    ticker_orig: str,\n",
    "    sector: str,\n",
    "    company_label: str,\n",
    "    polite_sleep: float = 0.7,\n",
    "    max_pages: Optional[int] = DEFAULT_MAX_PAGES,\n",
    "    save_html_debug: bool = False,\n",
    "    html_debug_dir: Path = Path(\"./_html_debug\"),\n",
    ") -> List[Dict]:\n",
    "    url_base = normalize_news_url(link_news)\n",
    "    if not url_base:\n",
    "        log.warning(f\"[{company_label}] Link News vazio.\")\n",
    "        return []\n",
    "\n",
    "    first_url = page_url(url_base, 1)\n",
    "    r1 = fetch(first_url)\n",
    "    if not r1:\n",
    "        log.warning(f\"[{company_label}] Não foi possível carregar a página 1: {first_url}\")\n",
    "        return []\n",
    "\n",
    "    if save_html_debug:\n",
    "        html_debug_dump(r1.text, company_label, 1, html_debug_dir)\n",
    "\n",
    "    items = parse_news_items(r1.text, ticker_orig, sector)\n",
    "    log.info(f\"[{company_label}] p1: {len(items)} items.\")\n",
    "\n",
    "    last_page = guess_last_page(r1.text)\n",
    "    if last_page is None:\n",
    "        # fallback: iterar enquanto vier notícia (parando após X vazias seguidas)\n",
    "        page = 2\n",
    "        empty_streak = 0\n",
    "        while True:\n",
    "            if max_pages and page > max_pages:\n",
    "                log.info(f\"[{company_label}] max_pages atingido ({max_pages}).\")\n",
    "                break\n",
    "\n",
    "            url = page_url(url_base, page)\n",
    "            time.sleep(polite_sleep)\n",
    "            r = fetch(url)\n",
    "            if not r:\n",
    "                empty_streak += 1\n",
    "                log.debug(f\"[{company_label}] página {page} falhou ({empty_streak} vazias).\")\n",
    "                if empty_streak >= 3:\n",
    "                    log.info(f\"[{company_label}] 3 páginas vazias seguidas; encerrando.\")\n",
    "                    break\n",
    "                page += 1\n",
    "                continue\n",
    "\n",
    "            if save_html_debug:\n",
    "                html_debug_dump(r.text, company_label, page, html_debug_dir)\n",
    "\n",
    "            chunk = parse_news_items(r.text, ticker_orig, sector)\n",
    "            log.info(f\"[{company_label}] p{page}: {len(chunk)} items.\")\n",
    "            if not chunk:\n",
    "                empty_streak += 1\n",
    "                if empty_streak >= 3:\n",
    "                    log.info(f\"[{company_label}] 3 páginas sem itens; encerrando.\")\n",
    "                    break\n",
    "            else:\n",
    "                items.extend(chunk)\n",
    "                empty_streak = 0\n",
    "            page += 1\n",
    "    else:\n",
    "        total_pages = last_page\n",
    "        if max_pages:\n",
    "            total_pages = min(total_pages, max_pages)\n",
    "        for page in range(2, total_pages + 1):\n",
    "            url = page_url(url_base, page)\n",
    "            time.sleep(polite_sleep)\n",
    "            r = fetch(url)\n",
    "            if not r:\n",
    "                log.debug(f\"[{company_label}] Falha ao carregar p{page}.\")\n",
    "                continue\n",
    "\n",
    "            if save_html_debug:\n",
    "                html_debug_dump(r.text, company_label, page, html_debug_dir)\n",
    "\n",
    "            chunk = parse_news_items(r.text, ticker_orig, sector)\n",
    "            log.info(f\"[{company_label}] p{page}: {len(chunk)} items.\")\n",
    "            items.extend(chunk)\n",
    "\n",
    "    return items\n",
    "\n",
    "# ---------------- Execução principal ----------------\n",
    "def read_excel(excel_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_excel(excel_path)\n",
    "    expected_cols = {\n",
    "        \"Empresa\", \"Setor\", \"Ticker BDR\", \"Ticker Original (EUA)\", \"Bolsa (EUA)\", \"Link News\",\n",
    "    }\n",
    "    missing = expected_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Colunas faltantes no Excel: {sorted(missing)}\")\n",
    "    return df\n",
    "\n",
    "def merge_incremental(df_new: pd.DataFrame, out_parquet: Path) -> pd.DataFrame:\n",
    "    if out_parquet.exists():\n",
    "        df_old = pd.read_parquet(out_parquet)\n",
    "        df_all = pd.concat([df_old, df_new], ignore_index=True)\n",
    "        df_all = df_all.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "        return df_all\n",
    "    return df_new\n",
    "\n",
    "def sort_by_datetime(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def _safe_parse_iso(x):\n",
    "        try:\n",
    "            return du.parse(x)\n",
    "        except Exception:\n",
    "            return None\n",
    "    if \"datetime\" in df.columns:\n",
    "        df[\"_dt_sort\"] = df[\"datetime\"].map(_safe_parse_iso)\n",
    "        df = df.sort_values(\"_dt_sort\", ascending=False).drop(columns=[\"_dt_sort\"])\n",
    "    return df\n",
    "\n",
    "def run(\n",
    "    excel: Path,\n",
    "    out_parquet: Path,\n",
    "    only: Optional[str],\n",
    "    max_pages: Optional[int],\n",
    "    resume: bool,\n",
    "    save_html_debug: bool,\n",
    "    workers: int,\n",
    "):\n",
    "    df_ref = read_excel(excel)\n",
    "\n",
    "    # filtro --only por ticker original OU empresa (case-insensitive, contém)\n",
    "    if only:\n",
    "        mask = (\n",
    "            df_ref[\"Ticker Original (EUA)\"].astype(str).str.contains(only, case=False, na=False) |\n",
    "            df_ref[\"Empresa\"].astype(str).str.contains(only, case=False, na=False)\n",
    "        )\n",
    "        df_ref = df_ref[mask].copy()\n",
    "        log.info(f\"Filtrando --only '{only}'. {len(df_ref)} linha(s) no Excel após filtro.\")\n",
    "\n",
    "    all_rows: List[Dict] = []\n",
    "\n",
    "    # processamento sequencial (simples e mais debugável)\n",
    "    for _, row in tqdm(df_ref.iterrows(), total=len(df_ref), desc=\"Empresas\"):\n",
    "        empresa = str(row[\"Empresa\"]).strip()\n",
    "        setor = str(row[\"Setor\"]).strip()\n",
    "        ticker_orig = str(row[\"Ticker Original (EUA)\"]).strip()\n",
    "        link_news = str(row[\"Link News\"]).strip()\n",
    "\n",
    "        if not link_news or link_news.lower() == \"nan\":\n",
    "            log.warning(f\"[{empresa}] Link News vazio; pulando.\")\n",
    "            continue\n",
    "\n",
    "        label = ticker_orig or empresa\n",
    "        items = scrape_company(\n",
    "            link_news=link_news,\n",
    "            ticker_orig=ticker_orig or empresa,\n",
    "            sector=setor,\n",
    "            company_label=label,\n",
    "            polite_sleep=0.7,\n",
    "            max_pages=max_pages if max_pages is not None else DEFAULT_MAX_PAGES,\n",
    "            save_html_debug=save_html_debug,\n",
    "        )\n",
    "        if not items:\n",
    "            log.info(f\"[{label}] Nenhuma notícia encontrada.\")\n",
    "            continue\n",
    "\n",
    "        df_company = pd.DataFrame(items).drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "\n",
    "        if resume and out_parquet.exists():\n",
    "            df_merged = merge_incremental(df_company, out_parquet)\n",
    "            df_merged = sort_by_datetime(df_merged)\n",
    "            df_merged.to_parquet(out_parquet, index=False)\n",
    "            log.info(f\"[{label}] Merge incremental -> {len(df_merged)} linhas em {out_parquet}\")\n",
    "        else:\n",
    "            all_rows.extend(df_company.to_dict(\"records\"))\n",
    "\n",
    "    # flush final quando não está em modo resume\n",
    "    if not resume and all_rows:\n",
    "        df = pd.DataFrame(all_rows).drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "        df = sort_by_datetime(df)\n",
    "        df.to_parquet(out_parquet, index=False)\n",
    "        log.info(f\"Salvo {len(df):,} notícias em {out_parquet}\")\n",
    "    elif not all_rows and not out_parquet.exists():\n",
    "        log.warning(\"Nenhuma notícia encontrada e arquivo de saída ainda não existe.\")\n",
    "\n",
    "# ---------------- CLI ----------------\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(description=\"Scraper de notícias do Investing.com (PT-BR)\")\n",
    "    p.add_argument(\"--excel\", default=DEFAULT_EXCEL, help=\"Caminho do Excel de referência\")\n",
    "    p.add_argument(\"--out\", default=DEFAULT_OUT, help=\"Arquivo Parquet de saída\")\n",
    "    p.add_argument(\"--only\", default=None, help=\"Filtra por Ticker Original (EUA) ou Empresa (contém, case-insensitive)\")\n",
    "    p.add_argument(\"--max-pages\", type=int, default=DEFAULT_MAX_PAGES, help=\"Limite máx. de páginas por ativo (padrão 15)\")\n",
    "    p.add_argument(\"--resume\", action=\"store_true\", help=\"Mescla incremental com parquet existente (checkpoint por empresa)\")\n",
    "    p.add_argument(\"--save-html-debug\", action=\"store_true\", help=\"Salva HTML das páginas em ./_html_debug\")\n",
    "    p.add_argument(\"--workers\", type=int, default=1, help=\"(reservado) Nº de workers em paralelo (mantido sequencial por debug)\")\n",
    "    p.add_argument(\"--verbose\", action=\"store_true\", help=\"Logs detalhados (DEBUG)\")\n",
    "    p.add_argument(\"--debug\", action=\"store_true\", help=\"Equivalente a --verbose\")\n",
    "\n",
    "    # tolerar args estranhos do Jupyter/VSCode:\n",
    "    args, _unknown = p.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def main():\n",
    "    import sys\n",
    "    # sanitiza argv quando rodar dentro de notebooks com ipykernel\n",
    "    if any(\"ipykernel\" in x for x in sys.argv):\n",
    "        # mantém os próprios args reconhecidos, graças ao parse_known_args acima\n",
    "        pass\n",
    "\n",
    "    args = parse_args()\n",
    "    setup_logging(verbose=args.verbose or args.debug, debug=args.debug)\n",
    "\n",
    "    excel = Path(args.excel)\n",
    "    out_parquet = Path(args.out)\n",
    "\n",
    "    log.info(f\"Excel: {excel.resolve()}\")\n",
    "    log.info(f\"Saída: {out_parquet.resolve()}\")\n",
    "    if args.only:\n",
    "        log.info(f\"Filtro --only: {args.only}\")\n",
    "    log.info(f\"Limite de páginas: {args.max_pages}\")\n",
    "    if args.resume:\n",
    "        log.info(\"Modo incremental: ON\")\n",
    "    if args.save_html_debug:\n",
    "        log.info(\"Salvar HTML debug: ON\")\n",
    "\n",
    "    try:\n",
    "        run(\n",
    "            excel=excel,\n",
    "            out_parquet=out_parquet,\n",
    "            only=args.only,\n",
    "            max_pages=args.max_pages,\n",
    "            resume=args.resume,\n",
    "            save_html_debug=args.save_html_debug,\n",
    "            workers=args.workers,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        log.exception(f\"Falha fatal: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be5e51fd-5ce5-5f20-a5fc-7a5783813a05</td>\n",
       "      <td>2025-10-15T17:28:56.072530-03:00</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Apple lança novas versões de MacBook, iPad e h...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/stock-market-new...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56dc0ac0-edb7-57ea-a6e6-2052f91d0e60</td>\n",
       "      <td>2025-10-15T11:28:56.072778-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>UBS: Tempos de espera para iPhone 17 continuam...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/stock-market-new...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238d7af7-c297-56c8-a865-de1b58394c29</td>\n",
       "      <td>2025-10-15T10:28:56.073472-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Apple recebe atualização de classificação de a...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/pro/bofa-sobre-a...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21111957-bafa-575b-9913-7125f7f2782f</td>\n",
       "      <td>2025-10-15T10:28:56.073367-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Apple anuncia chip M5 com desempenho de IA 4 v...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/assorted/apple-a...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7af568fb-59b5-501b-9c3b-8030d4373300</td>\n",
       "      <td>2025-10-15T10:28:56.073270-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Apple lança MacBook Pro de 14 polegadas com ch...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/assorted/apple-l...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7749</th>\n",
       "      <td>64952411-9287-5126-8329-1f9ca3897b15</td>\n",
       "      <td>2014-04-02T10:38:00-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Bolsas dos EUA sobem antes de dados; Dow Jones...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/stock-market-new...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>a0d552a5-007a-5492-90dd-35409b592920</td>\n",
       "      <td>2014-03-31T13:39:00-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Bolsas dos EUA abrem em alta, discurso de Yell...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/stock-market-new...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>b860f070-bf1a-547a-a739-735c04969fe8</td>\n",
       "      <td>2014-03-31T10:39:00-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Bolsas dos EUA sobem com especulações de estím...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/stock-market-new...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>a2e68f61-9668-53f7-8402-945bb287279f</td>\n",
       "      <td>2014-03-25T13:38:00-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Bolsas dos EUA abrem em alta após relatório im...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/stock-market-new...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7753</th>\n",
       "      <td>eb76dcb3-d4f0-594b-913c-928215d78cfb</td>\n",
       "      <td>2014-03-25T11:43:00-03:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>Bolsas dos EUA sobem antes de dados; Dow Jones...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>BR</td>\n",
       "      <td>https://br.investing.com/news/stock-market-new...</td>\n",
       "      <td>pt-BR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7754 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id                          datetime  \\\n",
       "0     be5e51fd-5ce5-5f20-a5fc-7a5783813a05  2025-10-15T17:28:56.072530-03:00   \n",
       "1     56dc0ac0-edb7-57ea-a6e6-2052f91d0e60  2025-10-15T11:28:56.072778-03:00   \n",
       "2     238d7af7-c297-56c8-a865-de1b58394c29  2025-10-15T10:28:56.073472-03:00   \n",
       "3     21111957-bafa-575b-9913-7125f7f2782f  2025-10-15T10:28:56.073367-03:00   \n",
       "4     7af568fb-59b5-501b-9c3b-8030d4373300  2025-10-15T10:28:56.073270-03:00   \n",
       "...                                    ...                               ...   \n",
       "7749  64952411-9287-5126-8329-1f9ca3897b15         2014-04-02T10:38:00-03:00   \n",
       "7750  a0d552a5-007a-5492-90dd-35409b592920         2014-03-31T13:39:00-03:00   \n",
       "7751  b860f070-bf1a-547a-a739-735c04969fe8         2014-03-31T10:39:00-03:00   \n",
       "7752  a2e68f61-9668-53f7-8402-945bb287279f         2014-03-25T13:38:00-03:00   \n",
       "7753  eb76dcb3-d4f0-594b-913c-928215d78cfb         2014-03-25T11:43:00-03:00   \n",
       "\n",
       "             source                                           headline ticker  \\\n",
       "0           Reuters  Apple lança novas versões de MacBook, iPad e h...   AAPL   \n",
       "1     Investing.com  UBS: Tempos de espera para iPhone 17 continuam...   AAPL   \n",
       "2     Investing.com  Apple recebe atualização de classificação de a...   AAPL   \n",
       "3     Investing.com  Apple anuncia chip M5 com desempenho de IA 4 v...   AAPL   \n",
       "4     Investing.com  Apple lança MacBook Pro de 14 polegadas com ch...   AAPL   \n",
       "...             ...                                                ...    ...   \n",
       "7749  Investing.com  Bolsas dos EUA sobem antes de dados; Dow Jones...   AAPL   \n",
       "7750  Investing.com  Bolsas dos EUA abrem em alta, discurso de Yell...   AAPL   \n",
       "7751  Investing.com  Bolsas dos EUA sobem com especulações de estím...   AAPL   \n",
       "7752  Investing.com  Bolsas dos EUA abrem em alta após relatório im...   AAPL   \n",
       "7753  Investing.com  Bolsas dos EUA sobem antes de dados; Dow Jones...   AAPL   \n",
       "\n",
       "          sector country                                                url  \\\n",
       "0     Tecnologia      BR  https://br.investing.com/news/stock-market-new...   \n",
       "1     Tecnologia      BR  https://br.investing.com/news/stock-market-new...   \n",
       "2     Tecnologia      BR  https://br.investing.com/news/pro/bofa-sobre-a...   \n",
       "3     Tecnologia      BR  https://br.investing.com/news/assorted/apple-a...   \n",
       "4     Tecnologia      BR  https://br.investing.com/news/assorted/apple-l...   \n",
       "...          ...     ...                                                ...   \n",
       "7749  Tecnologia      BR  https://br.investing.com/news/stock-market-new...   \n",
       "7750  Tecnologia      BR  https://br.investing.com/news/stock-market-new...   \n",
       "7751  Tecnologia      BR  https://br.investing.com/news/stock-market-new...   \n",
       "7752  Tecnologia      BR  https://br.investing.com/news/stock-market-new...   \n",
       "7753  Tecnologia      BR  https://br.investing.com/news/stock-market-new...   \n",
       "\n",
       "     language  \n",
       "0       pt-BR  \n",
       "1       pt-BR  \n",
       "2       pt-BR  \n",
       "3       pt-BR  \n",
       "4       pt-BR  \n",
       "...       ...  \n",
       "7749    pt-BR  \n",
       "7750    pt-BR  \n",
       "7751    pt-BR  \n",
       "7752    pt-BR  \n",
       "7753    pt-BR  \n",
       "\n",
       "[7754 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dados = pd.read_parquet(\"../data/investing_news.parquet\")\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pegar as 10 primeiras linhas\n",
    "sample = dados.head(10)\n",
    "sample.to_csv(\"sample_bdrs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
