{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e2b0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ADR↔BDR ETL + baseline com regra EOD especial:\n",
    " - BDR: shift base = -30min; última barra do dia (EOD) = -60min (p/ mapear 17:30→16:30 US)\n",
    " - ADR/FX: sem shift\n",
    " - merge_asof (nearest) com tolerância\n",
    " - ratio (OLS/median), teórico, spread, zscore\n",
    " - salva Parquet/CSV e plota séries\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "PATH_BDR_XLSX = Path(\"Hist_BDRs.xlsx\")\n",
    "PATH_US_XLSX  = Path(\"Hist_Origem_BDRs.xlsx\")\n",
    "PATH_FX_XLSX  = Path(\"dolar.xlsx\")\n",
    "\n",
    "OUT_DIR = Path(\"output\")\n",
    "(OUT_DIR / \"pairs\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"plots\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PAIRS = {\n",
    "    \"AAPL34\": \"AAPL\",\n",
    "    \"MSFT34\": \"MSFT\",\n",
    "    \"NVDC34\": \"NVDA\",\n",
    "    \"AMZO34\": \"AMZN\",\n",
    "    \"GOGL34\": \"GOOGL\",\n",
    "    \"M1TA34\": \"META\",\n",
    "    \"TSLA34\": \"TSLA\",\n",
    "    \"TSMC34\": \"TSM\",\n",
    "    \"AVGO34\": \"AVGO\",\n",
    "    \"BABA34\": \"BABA\",\n",
    "    \"JDCO34\": \"JD\",\n",
    "}\n",
    "\n",
    "# Alinhamento\n",
    "SHIFT_BDR_BASE_MIN = -30      # regra geral (casar :00 da B3 com :30 dos EUA)\n",
    "SHIFT_BDR_EOD_MIN  = -60      # somente última barra do dia (mapear 17:30→16:30)\n",
    "ASOF_TOL           = \"31min\"  # tolerância do merge_asof\n",
    "EWMA_SPAN          = 60\n",
    "RATIO_METHOD       = \"ols\"    # \"ols\" ou \"median\"\n",
    "MIN_OVERLAP        = 500\n",
    "PLOT_TOP_N         = None     # None = plotar todos os pares processados; ou ex.: 5\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "\n",
    "def _ptbr_to_float(series: pd.Series) -> pd.Series:\n",
    "    return (series.astype(float))\n",
    "\n",
    "def load_bdr_sheets(path: Path) -> dict[str, pd.DataFrame]:\n",
    "    raw = pd.read_excel(path, sheet_name=None)\n",
    "    out = {}\n",
    "    for sheet, df in raw.items():\n",
    "        if 'Data' not in df.columns or 'Fechamento' not in df.columns:\n",
    "            continue\n",
    "        df = df.rename(columns={\n",
    "            'Data':'datetime', 'Fechamento':'close_bdr', 'Volume Financeiro':'volume_bdr'\n",
    "        })\n",
    "        df['datetime']  = pd.to_datetime(df['datetime'], dayfirst=True)\n",
    "        df['close_bdr'] = _ptbr_to_float(df['close_bdr'])\n",
    "        if 'volume_bdr' in df:\n",
    "            try:\n",
    "                df['volume_bdr'] = _ptbr_to_float(df['volume_bdr'])\n",
    "            except Exception:\n",
    "                df['volume_bdr'] = pd.to_numeric(df['volume_bdr'], errors='coerce')\n",
    "        else:\n",
    "            df['volume_bdr'] = np.nan\n",
    "        df = (df[['datetime','close_bdr','volume_bdr']]\n",
    "                .dropna(subset=['datetime','close_bdr'])\n",
    "                .sort_values('datetime')\n",
    "                .set_index('datetime'))\n",
    "        out[sheet] = df\n",
    "    return out\n",
    "\n",
    "def load_us_sheets(path: Path) -> dict[str, pd.DataFrame]:\n",
    "    raw = pd.read_excel(path, sheet_name=None)\n",
    "    out = {}\n",
    "    for sheet, df in raw.items():\n",
    "        if 'Date' not in df.columns or 'Last Price' not in df.columns:\n",
    "            continue\n",
    "        df = df.rename(columns={'Date':'datetime','Last Price':'close_us','Volume':'volume_us'})\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], dayfirst=True)\n",
    "        try:\n",
    "            df['close_us'] = _ptbr_to_float(df['close_us'])\n",
    "        except Exception:\n",
    "            df['close_us'] = pd.to_numeric(df['close_us'], errors='coerce')\n",
    "        if 'volume_us' in df:\n",
    "            try:\n",
    "                df['volume_us'] = _ptbr_to_float(df['volume_us'])\n",
    "            except Exception:\n",
    "                df['volume_us'] = pd.to_numeric(df['volume_us'], errors='coerce')\n",
    "        else:\n",
    "            df['volume_us'] = np.nan\n",
    "        df = (df[['datetime','close_us','volume_us']]\n",
    "                .dropna(subset=['datetime','close_us'])\n",
    "                .sort_values('datetime')\n",
    "                .set_index('datetime'))\n",
    "        out[sheet] = df\n",
    "    return out\n",
    "\n",
    "def load_fx(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path)\n",
    "    if 'Date' not in df.columns or 'Mid Price' not in df.columns:\n",
    "        raise ValueError(\"dolar.xlsx precisa conter colunas 'Date' e 'Mid Price'.\")\n",
    "    df = df.rename(columns={'Date':'datetime','Mid Price':'usdxbrl','Volume':'volume_fx'})\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], dayfirst=True)\n",
    "    try:\n",
    "        df['usdxbrl'] = _ptbr_to_float(df['usdxbrl'])\n",
    "    except Exception:\n",
    "        df['usdxbrl'] = pd.to_numeric(df['usdxbrl'], errors='coerce')\n",
    "    if 'volume_fx' in df:\n",
    "        try:\n",
    "            df['volume_fx'] = _ptbr_to_float(df['volume_fx'])\n",
    "        except Exception:\n",
    "            df['volume_fx'] = pd.to_numeric(df['volume_fx'], errors='coerce')\n",
    "    else:\n",
    "        df['volume_fx'] = np.nan\n",
    "    df = (df[['datetime','usdxbrl','volume_fx']]\n",
    "            .dropna(subset=['datetime','usdxbrl'])\n",
    "            .sort_values('datetime')\n",
    "            .set_index('datetime'))\n",
    "    return df\n",
    "\n",
    "def shift_bdr_index_with_eod_rule(df_bdr: pd.DataFrame,\n",
    "                                  base_min: int = -30,\n",
    "                                  eod_min: int = -60) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aplica -30min em TODAS as barras e -60min apenas na ÚLTIMA barra de cada dia.\n",
    "    Isso mapeia 17:30(BR) → 16:30(US) e o restante :00 → :30.\n",
    "    \"\"\"\n",
    "    out = df_bdr.copy()\n",
    "    idx = out.index\n",
    "\n",
    "    # Série com o próprio índice (para poder agrupar e transformar)\n",
    "    idx_s = pd.Series(idx, index=idx)  # valores = timestamps\n",
    "\n",
    "    # Último timestamp de cada dia\n",
    "    last_per_day = idx_s.groupby(idx_s.index.normalize()).transform('max')\n",
    "\n",
    "    is_last = (idx_s == last_per_day)\n",
    "\n",
    "    base_delta = pd.to_timedelta(base_min, unit='m')\n",
    "    eod_delta  = pd.to_timedelta(eod_min,  unit='m')\n",
    "\n",
    "    new_idx = idx + base_delta\n",
    "    new_idx = pd.DatetimeIndex(new_idx)\n",
    "\n",
    "    # aplica offset EOD somente nos last-of-day\n",
    "    new_idx = pd.DatetimeIndex(np.where(is_last.values,\n",
    "                                        (idx + eod_delta).values,\n",
    "                                        new_idx.values))\n",
    "    out.index = new_idx\n",
    "    return out.sort_index()\n",
    "\n",
    "def nearest_join(left: pd.DataFrame, right: pd.DataFrame, tolerance: str, direction: str = \"backward\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Junta pela observação passada mais recente (<=) para evitar olhar para o futuro.\n",
    "    \"\"\"\n",
    "    l = left.sort_index().reset_index().rename(columns={'index':'datetime'})\n",
    "    r = right.sort_index().reset_index().rename(columns={'index':'datetime'})\n",
    "    m = pd.merge_asof(\n",
    "        l, r, on='datetime',\n",
    "        direction=direction,\n",
    "        tolerance=pd.to_timedelta(tolerance)\n",
    "    )\n",
    "    m = m.set_index('datetime')\n",
    "    return m\n",
    "\n",
    "def calibrate_ratio(bdr_close: pd.Series, adr_usd: pd.Series, usdxbrl: pd.Series, method=\"ols\"):\n",
    "    denom = adr_usd * usdxbrl\n",
    "    df = pd.DataFrame({'bdr': bdr_close, 'den': denom}).dropna()\n",
    "    if df.empty:\n",
    "        return np.nan, np.nan, 0\n",
    "    ratio_series = df['bdr'] / df['den'].replace(0, np.nan)\n",
    "    ratio_series = ratio_series.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if ratio_series.empty:\n",
    "        return np.nan, np.nan, int(len(df))\n",
    "    if method == \"median\":\n",
    "        ratio = float(np.median(ratio_series.values))\n",
    "    else:\n",
    "        num = (df['den'] * df['bdr']).sum()\n",
    "        den = (df['den'] ** 2).sum()\n",
    "        ratio = float(num / den) if den != 0 else np.nan\n",
    "    return ratio, float(ratio_series.std(ddof=1)), int(len(ratio_series))\n",
    "\n",
    "def add_theoretical_and_spread(df_pair: pd.DataFrame, ewma_span=60) -> pd.DataFrame:\n",
    "    df = df_pair.copy()\n",
    "    df['bdr_teo'] = df['close_us'] * df['usdxbrl'] * df.attrs['ratio_used']\n",
    "    df['spread']  = np.log(df['close_bdr']) - np.log(df['bdr_teo'])\n",
    "    mean = df['spread'].ewm(span=ewma_span).mean()\n",
    "    var  = df['spread'].ewm(span=ewma_span).var()\n",
    "    std  = np.sqrt(var)\n",
    "    df['zscore'] = (df['spread'] - mean) / std.replace(0, np.nan)\n",
    "    return df\n",
    "\n",
    "def plot_prices(df: pd.DataFrame, name: str, outdir: Path):\n",
    "    fig = plt.figure()\n",
    "    df[['close_bdr','bdr_teo']].dropna().plot(ax=plt.gca())\n",
    "    plt.title(f\"{name} — BDR vs Teórico\")\n",
    "    plt.xlabel(\"Tempo\"); plt.ylabel(\"Preço (BRL)\")\n",
    "    fig.tight_layout(); fig.savefig(outdir / f\"{name}_prices.png\"); plt.close(fig)\n",
    "\n",
    "def plot_spread(df: pd.DataFrame, name: str, outdir: Path):\n",
    "    fig = plt.figure()\n",
    "    df['spread'].dropna().plot(ax=plt.gca())\n",
    "    plt.title(f\"{name} — Spread (log BDR − log Teórico)\")\n",
    "    plt.xlabel(\"Tempo\"); plt.ylabel(\"Spread (log)\")\n",
    "    fig.tight_layout(); fig.savefig(outdir / f\"{name}_spread.png\"); plt.close(fig)\n",
    "\n",
    "def plot_zscore(df: pd.DataFrame, name: str, outdir: Path):\n",
    "    fig = plt.figure()\n",
    "    df['zscore'].dropna().plot(ax=plt.gca())\n",
    "    plt.title(f\"{name} — Z-Score do Spread (EWMA)\")\n",
    "    plt.xlabel(\"Tempo\"); plt.ylabel(\"Z-Score\")\n",
    "    ax = plt.gca(); ax.axhline(0); ax.axhline(2); ax.axhline(-2)\n",
    "    fig.tight_layout(); fig.savefig(outdir / f\"{name}_zscore.png\"); plt.close(fig)\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31041449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bars_per_day_from_index(index: pd.DatetimeIndex) -> int:\n",
    "    if len(index) == 0:\n",
    "        return 1\n",
    "    counts = pd.Series(index.normalize()).value_counts()\n",
    "    return int(np.median(counts.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91eebfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostics_quick(df_pair: pd.DataFrame):\n",
    "    \"\"\"Retorna dict com checagens rápidas do par casado.\"\"\"\n",
    "    x = np.log(df_pair['close_bdr'])\n",
    "    y = np.log(df_pair['close_us'] * df_pair['usdxbrl'])\n",
    "    valid = x.notna() & y.notna()\n",
    "    corr = x[valid].corr(y[valid]) if valid.any() else np.nan\n",
    "    ratio_inst = (df_pair['close_bdr'] / (df_pair['close_us'] * df_pair['usdxbrl'])).replace([np.inf,-np.inf], np.nan)\n",
    "    med_ratio = float(ratio_inst.median())\n",
    "    return {\n",
    "        \"corr_log\": float(corr),\n",
    "        \"median_ratio\": med_ratio,\n",
    "        \"n\": int(valid.sum()),\n",
    "    }\n",
    "\n",
    "def choose_ratio_with_fallback(df_pair: pd.DataFrame, ratio_ols: float):\n",
    "    \"\"\"Compara OLS com mediana e aplica fallback se OLS for inconsistente.\"\"\"\n",
    "    denom = df_pair['close_us'] * df_pair['usdxbrl']\n",
    "    ratio_series = (df_pair['close_bdr'] / denom).replace([np.inf,-np.inf], np.nan).dropna()\n",
    "    if ratio_series.empty:\n",
    "        return ratio_ols, np.nan, 0, \"ols\"\n",
    "    ratio_med = float(np.median(ratio_series))\n",
    "    ratio_sd = float(ratio_series.std(ddof=1)) if len(ratio_series) > 1 else 0.0\n",
    "    # regra: se OLS for < 1/100 de ratio_med (ordens de grandeza), usa mediana\n",
    "    if (ratio_med > 0) and (ratio_ols <= 0 or ratio_ols < ratio_med / 100.0 or ratio_ols > ratio_med * 100.0):\n",
    "        return ratio_med, ratio_sd, len(ratio_series), \"median_fallback\"\n",
    "    return ratio_ols, ratio_sd, len(ratio_series), \"ols\"\n",
    "\n",
    "def rank_score_stable(overlap, mae, ratio_sd, k1=1000.0, k2=100000.0):\n",
    "    # ln(1+overlap) - ln(1+k1*mae) - ln(1+k2*ratio_sd)\n",
    "    return (np.log1p(overlap)\n",
    "            - np.log1p(k1 * max(mae, 0.0))\n",
    "            - np.log1p(k2 * max(ratio_sd, 0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "684c514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_spread(df: pd.DataFrame,\n",
    "                    z_entry=2.0, z_exit=0.0, z_stop=3.0,\n",
    "                    cost_bdr_bps=10.0, cost_synth_bps=2.0,\n",
    "                    borrow_bdr_bps_day=40.0,\n",
    "                    bars_per_day=None,\n",
    "                    flat_at_eod=True,\n",
    "                    min_hold=2,\n",
    "                    no_entry_last_k_bars=2,\n",
    "                    latency_bars=0):\n",
    "    \"\"\"\n",
    "    Opera S = BDR - bdr_teo (BRL).\n",
    "    Entra: z > +z_entry -> short S ; z < -z_entry -> long S\n",
    "    Sai: z cruza z_exit (0) OU |z| > z_stop OU fim do dia (se flat_at_eod).\n",
    "    Restrições:\n",
    "      - não entra nas últimas K barras do dia (no_entry_last_k_bars)\n",
    "      - tempo mínimo em posição (min_hold)\n",
    "      - pode simular latência de execução (latency_bars >= 0)\n",
    "    Custos: mudança de posição em bps + borrow diário quando short BDR.\n",
    "    \"\"\"\n",
    "    df = df.copy().sort_index()\n",
    "    S = df['close_bdr'] - df['bdr_teo']\n",
    "    z = df['zscore']; bdr = df['close_bdr']; syn = df['bdr_teo']\n",
    "\n",
    "    idx = df.index\n",
    "    day = idx.normalize()\n",
    "    # marca última barra do dia e também as K últimas\n",
    "    last_of_day = (day != np.roll(day, -1))\n",
    "    if len(df): last_of_day[-1] = True\n",
    "    # índice da barra do dia (0..n-1)\n",
    "    day_counts = pd.Series(day).map(pd.Series(day).value_counts())\n",
    "    bar_num_in_day = pd.Series(day).groupby(day).cumcount().to_numpy()\n",
    "    bars_in_day    = day_counts.to_numpy()\n",
    "    in_last_k = (bars_in_day - bar_num_in_day) <= no_entry_last_k_bars\n",
    "\n",
    "    if bars_per_day is None:\n",
    "        bars_per_day = estimate_bars_per_day_from_index(idx)\n",
    "    borrow_per_bar = (borrow_bdr_bps_day / max(bars_per_day, 1)) / 1e4\n",
    "\n",
    "    pos = np.zeros(len(df), dtype=int)\n",
    "    entry_idx = -np.ones(len(df), dtype=int)\n",
    "    costs = np.zeros(len(df))\n",
    "    pnl   = np.zeros(len(df))\n",
    "\n",
    "    def should_exit(i):\n",
    "        if pos[i-1] > 0 and z.iloc[i] >= z_exit: return True\n",
    "        if pos[i-1] < 0 and z.iloc[i] <= -z_exit: return True\n",
    "        if abs(z.iloc[i]) > z_stop: return True\n",
    "        if flat_at_eod and last_of_day[i]: return True\n",
    "        if min_hold > 0 and entry_idx[i-1] >= 0 and (i - entry_idx[i-1]) < min_hold:\n",
    "            return False\n",
    "        return False\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        p_prev = pos[i-1]\n",
    "\n",
    "        # decisão de entrada/saída com latência opcional\n",
    "        j = i - latency_bars if latency_bars > 0 else i\n",
    "\n",
    "        if p_prev == 0:\n",
    "            enter_long = (z.iloc[j] < -z_entry) if j >= 0 else False\n",
    "            enter_short= (z.iloc[j] >  z_entry) if j >= 0 else False\n",
    "            if not in_last_k[i]:  # bloqueio de entrada nas últimas K barras\n",
    "                if enter_short:\n",
    "                    pos[i] = -1; entry_idx[i] = i\n",
    "                elif enter_long:\n",
    "                    pos[i] = +1; entry_idx[i] = i\n",
    "                else:\n",
    "                    pos[i] = 0\n",
    "            else:\n",
    "                pos[i] = 0\n",
    "        else:\n",
    "            pos[i] = p_prev\n",
    "            entry_idx[i] = entry_idx[i-1] if entry_idx[i-1] >= 0 else i-1\n",
    "            if should_exit(i):\n",
    "                pos[i] = 0; entry_idx[i] = -1\n",
    "\n",
    "        # custos de mudança de posição\n",
    "        delta = abs(pos[i] - p_prev)\n",
    "        if delta > 0:\n",
    "            trade_notional = (cost_bdr_bps * bdr.iloc[i] + cost_synth_bps * syn.iloc[i]) / 1e4\n",
    "            costs[i] += delta * trade_notional\n",
    "\n",
    "        # aluguel enquanto carrego short de BDR\n",
    "        if p_prev < 0:\n",
    "            costs[i] += borrow_per_bar * bdr.iloc[i]\n",
    "\n",
    "        # PnL do período\n",
    "        pnl[i] = p_prev * (S.iloc[i] - S.iloc[i-1]) - costs[i]\n",
    "\n",
    "    # séries e métricas\n",
    "    pnl_cum = pnl.cumsum()\n",
    "    ret = pd.Series(pnl, index=df.index, name='pnl')\n",
    "    curve = pd.Series(pnl_cum, index=df.index, name='pnl_cum')\n",
    "\n",
    "    ann_factor = np.sqrt(1638.0)  # ~6.5h*252\n",
    "    std_ret = float(ret.std(ddof=1))\n",
    "    sharpe = (float(ret.mean()) / (std_ret + 1e-12)) * ann_factor if std_ret > 0 else np.nan\n",
    "\n",
    "    roll_max = curve.cummax()\n",
    "    mdd = float((curve - roll_max).min()) if len(curve) else np.nan\n",
    "\n",
    "    # métricas por trade\n",
    "    entries = (np.roll(pos, 1) == 0) & (pos != 0)\n",
    "    exits   = (np.roll(pos, 1) != 0) & (pos == 0)\n",
    "    starts = np.where(entries)[0].tolist()\n",
    "    ends   = np.where(exits)[0].tolist()\n",
    "    if ends and (not starts or ends[0] < starts[0]): ends.pop(0)\n",
    "    if len(ends) > len(starts): ends = ends[:len(starts)]\n",
    "    if len(starts) > len(ends): starts = starts[:len(ends)]\n",
    "\n",
    "    trade_pnls = [float(ret.iloc[s+1:e+1].sum()) for s, e in zip(starts, ends)]\n",
    "    hold_bars  = [int(e - s) for s, e in zip(starts, ends)]\n",
    "    trades     = len(trade_pnls)\n",
    "    winrate    = float(np.mean([p > 0 for p in trade_pnls])) if trades else np.nan\n",
    "    expectancy = float(np.mean(trade_pnls)) if trades else np.nan\n",
    "    med_hold   = int(np.median(hold_bars)) if hold_bars else 0\n",
    "\n",
    "    summary = {\n",
    "        'bars': len(df), 'trades': trades,\n",
    "        'winrate': winrate, 'expectancy_per_trade': expectancy,\n",
    "        'median_hold_bars': med_hold,\n",
    "        'sharpe_hourly_annualized': sharpe,\n",
    "        'mdd': mdd,\n",
    "        'pnl_total': float(curve.iloc[-1]) if len(curve) else 0.0,\n",
    "        'costs_total': float(costs.sum()),\n",
    "    }\n",
    "    out = pd.DataFrame({'S': S, 'z': z, 'pnl': ret, 'pnl_cum': curve, 'pos': pos}, index=df.index)\n",
    "    return out, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "450c32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_params(pairs_to_test,\n",
    "                       z_entries=(1.5, 2.0, 2.5),\n",
    "                       z_stops=(3.0, 3.5),\n",
    "                       cost_sets=((10.0, 2.0), (20.0, 5.0), (30.0, 10.0)),\n",
    "                       borrow_daily_bps=(0.0, 20.0, 50.0),\n",
    "                       flat_at_eod=True):\n",
    "    \"\"\"\n",
    "    pairs_to_test: lista de tuplas (bdr, adr, parquet_path) — use 'processed' do main.\n",
    "    Retorna um DataFrame com os resultados do grid (ou vazio, se nada rodar).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for bdr, adr, pq in pairs_to_test:\n",
    "        # carrega o par\n",
    "        df = pd.read_parquet(pq)\n",
    "        df = df.set_index(pd.to_datetime(df['datetime'])).drop(columns=['datetime'])\n",
    "        name = f\"{bdr}_{adr}\"\n",
    "\n",
    "        # estima barras/dia (pra custo de borrow)\n",
    "        bars_day = estimate_bars_per_day_from_index(df.index)\n",
    "\n",
    "        # grid\n",
    "        for ze in z_entries:\n",
    "            for zs in z_stops:\n",
    "                for cbdr, csyn in cost_sets:\n",
    "                    for brw in borrow_daily_bps:\n",
    "                        bt_df, bt_sum = backtest_spread(\n",
    "                            df,\n",
    "                            z_entry=ze, z_exit=0.5, z_stop=zs,   # use z_exit>0 p/ evitar saída imediata\n",
    "                            cost_bdr_bps=cbdr, cost_synth_bps=csyn,\n",
    "                            borrow_bdr_bps_day=brw,\n",
    "                            bars_per_day=bars_day,\n",
    "                            flat_at_eod=flat_at_eod,\n",
    "                            min_hold=2,\n",
    "                            no_entry_last_k_bars=2,\n",
    "                            latency_bars=0\n",
    "                        )\n",
    "                        rows.append({\n",
    "                            'pair': name,\n",
    "                            'z_entry': ze,\n",
    "                            'z_stop': zs,\n",
    "                            'cost_bdr_bps': cbdr,\n",
    "                            'cost_syn_bps': csyn,\n",
    "                            'borrow_bps_day': brw,\n",
    "                            **bt_sum\n",
    "                        })\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "\n",
    "    # Se deu vazio (ex.: pairs_to_test vazio), retorna DF vazio (sem tentar sort)\n",
    "    if df_out.empty:\n",
    "        return df_out\n",
    "\n",
    "    # Ordena com segurança\n",
    "    col = 'sharpe_hourly_annualized'\n",
    "    if col in df_out.columns:\n",
    "        df_out = df_out.sort_values(col, ascending=False)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2787c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostics_quick(df_pair: pd.DataFrame):\n",
    "    x = np.log(df_pair['close_bdr'])\n",
    "    y = np.log(df_pair['close_us'] * df_pair['usdxbrl'])\n",
    "    valid = x.notna() & y.notna()\n",
    "    corr = x[valid].corr(y[valid]) if valid.any() else np.nan\n",
    "    ratio_inst = (df_pair['close_bdr'] / (df_pair['close_us'] * df_pair['usdxbrl'])).replace([np.inf,-np.inf], np.nan)\n",
    "    return {\n",
    "        \"corr_log\": float(corr),\n",
    "        \"median_ratio\": float(ratio_inst.median()),\n",
    "        \"n\": int(valid.sum()),\n",
    "    }\n",
    "\n",
    "def choose_ratio_with_fallback(df_pair: pd.DataFrame, ratio_ols: float):\n",
    "    denom = df_pair['close_us'] * df_pair['usdxbrl']\n",
    "    ratio_series = (df_pair['close_bdr'] / denom).replace([np.inf,-np.inf], np.nan).dropna()\n",
    "    if ratio_series.empty:\n",
    "        return ratio_ols, np.nan, 0, \"ols\"\n",
    "    ratio_med = float(np.median(ratio_series))\n",
    "    ratio_sd = float(ratio_series.std(ddof=1)) if len(ratio_series) > 1 else 0.0\n",
    "    if (ratio_med > 0) and (ratio_ols <= 0 or ratio_ols < ratio_med/100.0 or ratio_ols > ratio_med*100.0):\n",
    "        return ratio_med, ratio_sd, len(ratio_series), \"median_fallback\"\n",
    "    return ratio_ols, ratio_sd, len(ratio_series), \"ols\"\n",
    "\n",
    "def rank_score_stable(overlap, mae, ratio_sd, k1=1000.0, k2=100000.0):\n",
    "    # ln(1+overlap) - ln(1+k1*mae) - ln(1+k2*ratio_sd)\n",
    "    return (np.log1p(overlap) - np.log1p(k1*max(mae,0.0)) - np.log1p(k2*max(ratio_sd,0.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "871fe76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entries_near_eod_share(df_bt: pd.DataFrame, df_raw: pd.DataFrame, last_k=2) -> float:\n",
    "    \"\"\"\n",
    "    Retorna a fração de entradas que ocorrem nas últimas 'last_k' barras do dia.\n",
    "    \"\"\"\n",
    "    idx = df_raw.index\n",
    "    day = idx.normalize()\n",
    "\n",
    "    # barras no dia e índice da barra (0..n-1) para cada linha\n",
    "    day_series = pd.Series(day)\n",
    "    bars_in_day = day_series.map(day_series.value_counts()).to_numpy()\n",
    "    bar_num_in_day = day_series.groupby(day_series).cumcount().to_numpy()\n",
    "\n",
    "    near_eod = (bars_in_day - bar_num_in_day) <= last_k  # bool de mesmo tamanho\n",
    "\n",
    "    pos = df_bt['pos'].to_numpy()\n",
    "    entries = (np.roll(pos, 1) == 0) & (pos != 0)        # pontos de entrada\n",
    "\n",
    "    num_entries = int(entries.sum())\n",
    "    if num_entries == 0:\n",
    "        return np.nan\n",
    "\n",
    "    num_near = int((entries & near_eod).sum())\n",
    "    return num_near / num_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "957bd075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo BDRs…\n",
      "BDRs lidas: 11\n",
      "Lendo ADRs…\n",
      "ADRs lidas: 11\n",
      "Lendo FX (USDBRL)…\n",
      "[OK] AAPL34↔AAPL: 12961 pts | ratio=0.049607 (ols) | salvo: AAPL34_AAPL.parquet\n",
      "[OK] MSFT34↔MSFT: 11007 pts | ratio=0.041243 (ols) | salvo: MSFT34_MSFT.parquet\n",
      "[OK] NVDC34↔NVDA: 8254 pts | ratio=0.020829 (ols) | salvo: NVDC34_NVDA.parquet\n",
      "[OK] AMZO34↔AMZN: 9708 pts | ratio=0.050004 (ols) | salvo: AMZO34_AMZN.parquet\n",
      "[OK] GOGL34↔GOOGL: 10794 pts | ratio=0.082713 (ols) | salvo: GOGL34_GOOGL.parquet\n",
      "[OK] M1TA34↔META: 9707 pts | ratio=0.035643 (ols) | salvo: M1TA34_META.parquet\n",
      "[OK] TSLA34↔TSLA: 8676 pts | ratio=0.031242 (ols) | salvo: TSLA34_TSLA.parquet\n",
      "[OK] TSMC34↔TSM: 7540 pts | ratio=0.122508 (ols) | salvo: TSMC34_TSM.parquet\n",
      "[OK] AVGO34↔AVGO: 5914 pts | ratio=0.014187 (ols) | salvo: AVGO34_AVGO.parquet\n",
      "[OK] BABA34↔BABA: 8194 pts | ratio=0.035744 (ols) | salvo: BABA34_BABA.parquet\n",
      "[OK] JDCO34↔JD: 5526 pts | ratio=0.166777 (ols) | salvo: JDCO34_JD.parquet\n",
      "\n",
      "== Resumo dos pares (top 10 por score) ==\n",
      "       bdr    adr  overlap_obs  ratio_used  ratio_sd  mae_teorico  \\\n",
      "2   NVDC34   NVDA         8254    0.020829  0.000142     0.025071   \n",
      "9   BABA34   BABA         8194    0.035744  0.000184     0.094435   \n",
      "3   AMZO34   AMZN         9708    0.050004  0.000281     0.128764   \n",
      "6   TSLA34   TSLA         8676    0.031242  0.000243     0.199063   \n",
      "5   M1TA34   META         9707    0.035643  0.000238     0.230080   \n",
      "8   AVGO34   AVGO         5914    0.014187  0.000337     0.105918   \n",
      "0   AAPL34   AAPL        12961    0.049607  0.001139     0.236555   \n",
      "4   GOGL34  GOOGL        10794    0.082713  0.000918     0.291579   \n",
      "10  JDCO34     JD         5526    0.166777  0.001184     0.186476   \n",
      "1   MSFT34   MSFT        11007    0.041243  0.001139     0.544713   \n",
      "\n",
      "    mape_teorico ratio_method  \n",
      "2       0.004789          ols  \n",
      "9       0.003697          ols  \n",
      "3       0.003634          ols  \n",
      "6       0.005416          ols  \n",
      "5       0.004156          ols  \n",
      "8       0.022407          ols  \n",
      "0       0.018538          ols  \n",
      "4       0.008161          ols  \n",
      "10      0.003831          ols  \n",
      "1       0.020815          ols  \n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] AAPL34_AAPL: sharpe=3.54 | pnl=86.79 | trades=250\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] MSFT34_MSFT: sharpe=2.84 | pnl=99.41 | trades=180\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] NVDC34_NVDA: sharpe=3.63 | pnl=17.97 | trades=170\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] AMZO34_AMZN: sharpe=3.33 | pnl=74.86 | trades=179\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] GOGL34_GOOGL: sharpe=3.15 | pnl=87.15 | trades=174\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] M1TA34_META: sharpe=3.16 | pnl=152.90 | trades=172\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] TSLA34_TSLA: sharpe=4.74 | pnl=163.77 | trades=229\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] TSMC34_TSM: sharpe=4.14 | pnl=155.85 | trades=157\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] AVGO34_AVGO: sharpe=3.47 | pnl=13.86 | trades=92\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] BABA34_BABA: sharpe=4.44 | pnl=61.78 | trades=202\n",
      "% de entradas nas últimas 2 barras do dia: 0.0%\n",
      "[BT] JDCO34_JD: sharpe=3.60 | pnl=64.27 | trades=114\n",
      "\n",
      "== Resultado do backtest (top 10 por Sharpe) ==\n",
      "       bdr    adr  sharpe_hourly_annualized   pnl_total       mdd  trades  \\\n",
      "6   TSLA34   TSLA                  4.740049  163.765303 -3.683568     229   \n",
      "9   BABA34   BABA                  4.440204   61.775975 -1.165276     202   \n",
      "7   TSMC34    TSM                  4.143151  155.853268 -3.357827     157   \n",
      "2   NVDC34   NVDA                  3.626907   17.968400 -0.449906     170   \n",
      "10  JDCO34     JD                  3.602383   64.266090 -2.996242     114   \n",
      "0   AAPL34   AAPL                  3.540638   86.785321 -1.195688     250   \n",
      "8   AVGO34   AVGO                  3.468548   13.857634 -0.340288      92   \n",
      "3   AMZO34   AMZN                  3.329759   74.864140 -3.733953     179   \n",
      "5   M1TA34   META                  3.158865  152.904140 -2.407334     172   \n",
      "4   GOGL34  GOOGL                  3.146978   87.149714 -3.057096     174   \n",
      "\n",
      "     winrate  corr_log  \n",
      "6   0.956332  0.999924  \n",
      "9   0.940594  0.999936  \n",
      "7   0.923567  0.999001  \n",
      "2   0.958824  0.999974  \n",
      "10  0.973684  0.999879  \n",
      "0   0.936000  0.999960  \n",
      "8   0.945652  0.999762  \n",
      "3   0.927374  0.999969  \n",
      "5   0.953488  0.999942  \n",
      "4   0.896552  0.999901  \n",
      "\n",
      "== Grid search (top 10 por Sharpe) ==\n",
      "            pair  z_entry  z_stop  cost_bdr_bps  cost_syn_bps  borrow_bps_day  \\\n",
      "330  TSLA34_TSLA      1.5     3.5          10.0           2.0             0.0   \n",
      "336  TSLA34_TSLA      1.5     4.0          10.0           2.0             0.0   \n",
      "324  TSLA34_TSLA      1.5     3.0          10.0           2.0             0.0   \n",
      "337  TSLA34_TSLA      1.5     4.0          10.0           2.0            20.0   \n",
      "331  TSLA34_TSLA      1.5     3.5          10.0           2.0            20.0   \n",
      "325  TSLA34_TSLA      1.5     3.0          10.0           2.0            20.0   \n",
      "492  BABA34_BABA      1.5     3.5          10.0           2.0             0.0   \n",
      "498  BABA34_BABA      1.5     4.0          10.0           2.0             0.0   \n",
      "486  BABA34_BABA      1.5     3.0          10.0           2.0             0.0   \n",
      "338  TSLA34_TSLA      1.5     4.0          10.0           2.0            40.0   \n",
      "\n",
      "     sharpe_hourly_annualized   pnl_total  trades   winrate  \n",
      "330                  7.016628  305.402867     494  0.957490  \n",
      "336                  7.016628  305.402867     494  0.957490  \n",
      "324                  6.994873  302.992702     495  0.953535  \n",
      "337                  6.861263  297.038407     494  0.951417  \n",
      "331                  6.861263  297.038407     494  0.951417  \n",
      "325                  6.838924  294.632316     495  0.947475  \n",
      "492                  6.826970  128.354601     482  0.954357  \n",
      "498                  6.824542  128.276373     482  0.954357  \n",
      "486                  6.774081  126.893337     482  0.950207  \n",
      "338                  6.702232  288.673947     494  0.945344  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Lendo BDRs…\")\n",
    "    bdr_map = load_bdr_sheets(PATH_BDR_XLSX)\n",
    "    print(f\"BDRs lidas: {len(bdr_map)}\")\n",
    "\n",
    "    print(\"Lendo ADRs…\")\n",
    "    us_map  = load_us_sheets(PATH_US_XLSX)\n",
    "    print(f\"ADRs lidas: {len(us_map)}\")\n",
    "\n",
    "    print(\"Lendo FX (USDBRL)…\")\n",
    "    fx_df   = load_fx(PATH_FX_XLSX)\n",
    "\n",
    "    rows_summary = []\n",
    "    processed = []\n",
    "\n",
    "    for bdr, adr in PAIRS.items():\n",
    "        if bdr not in bdr_map:\n",
    "            print(f\"[WARN] BDR '{bdr}' não encontrado; pulando.\")\n",
    "            continue\n",
    "        if adr not in us_map:\n",
    "            print(f\"[WARN] ADR '{adr}' não encontrado; pulando.\")\n",
    "            continue\n",
    "\n",
    "        # Shift especial no BDR (−30min geral; −60min na última barra do dia)\n",
    "        df_bdr_shifted = shift_bdr_index_with_eod_rule(\n",
    "            bdr_map[bdr], SHIFT_BDR_BASE_MIN, SHIFT_BDR_EOD_MIN\n",
    "        )\n",
    "\n",
    "        # Join BDR↔ADR↔FX (nearest)\n",
    "        tmp = nearest_join(\n",
    "            df_bdr_shifted[['close_bdr','volume_bdr']],\n",
    "            us_map[adr][['close_us','volume_us']],\n",
    "            ASOF_TOL\n",
    "        )\n",
    "        tmp = nearest_join(tmp, fx_df[['usdxbrl','volume_fx']], ASOF_TOL)\n",
    "        tmp = tmp.dropna(subset=['close_bdr','close_us','usdxbrl']).sort_index()\n",
    "\n",
    "        n_overlap = len(tmp)\n",
    "        if n_overlap == 0:\n",
    "            print(f\"[INFO] Sem overlap para {bdr}↔{adr}.\")\n",
    "            continue\n",
    "\n",
    "        # Ratio OLS + fallback para mediana (se necessário)\n",
    "        ratio_ols, ratio_sd_raw, n_ratio_raw = calibrate_ratio(\n",
    "            tmp['close_bdr'], tmp['close_us'], tmp['usdxbrl'], method=RATIO_METHOD\n",
    "        )\n",
    "        ratio_used, ratio_sd, n_ratio, ratio_method = choose_ratio_with_fallback(tmp, ratio_ols)\n",
    "\n",
    "        # Teórico, spread, zscore\n",
    "        tmp.attrs['ratio_used'] = ratio_used\n",
    "        tmp = add_theoretical_and_spread(tmp, ewma_span=EWMA_SPAN)\n",
    "\n",
    "        # Métricas de aderência do teórico\n",
    "        mae  = (tmp['close_bdr'] - tmp['bdr_teo']).abs().mean()\n",
    "        mape = ((tmp['close_bdr'] - tmp['bdr_teo']).abs()\n",
    "                / tmp['close_bdr'].replace(0, np.nan)).mean()\n",
    "\n",
    "        rows_summary.append({\n",
    "            'bdr': bdr,\n",
    "            'adr': adr,\n",
    "            'overlap_obs': n_overlap,\n",
    "            'ratio_used': ratio_used,\n",
    "            'ratio_sd': ratio_sd,\n",
    "            'ratio_obs': n_ratio,\n",
    "            'ratio_method': ratio_method,\n",
    "            'mae_teorico': mae,\n",
    "            'mape_teorico': mape,\n",
    "        })\n",
    "\n",
    "        # Salvar parquet do par casado\n",
    "        out_path = OUT_DIR / \"pairs\" / f\"{bdr}_{adr}.parquet\"\n",
    "        tmp.reset_index().rename(columns={'index':'datetime'}).to_parquet(out_path, index=False)\n",
    "        processed.append((bdr, adr, out_path))\n",
    "        print(f\"[OK] {bdr}↔{adr}: {n_overlap} pts | ratio={ratio_used:.6f} ({ratio_method}) | salvo: {out_path.name}\")\n",
    "\n",
    "    # Resumo + plots + backtest\n",
    "    if rows_summary:\n",
    "        df_sum = pd.DataFrame(rows_summary)\n",
    "\n",
    "        # Score estável (log-scale)\n",
    "        df_sum['score'] = df_sum.apply(\n",
    "            lambda r: rank_score_stable(r['overlap_obs'], r['mae_teorico'], r['ratio_sd']),\n",
    "            axis=1\n",
    "        )\n",
    "        df_sum = df_sum.sort_values('score', ascending=False)\n",
    "        df_sum.to_csv(OUT_DIR / \"summary_pairs.csv\", index=False, float_format=\"%.8f\")\n",
    "        print(\"\\n== Resumo dos pares (top 10 por score) ==\")\n",
    "        print(df_sum[['bdr','adr','overlap_obs','ratio_used','ratio_sd','mae_teorico','mape_teorico','ratio_method']].head(10))\n",
    "\n",
    "        # Quais pares plotar/backtestar\n",
    "        plot_list = processed\n",
    "        if PLOT_TOP_N is not None and PLOT_TOP_N > 0:\n",
    "            top = set(tuple(x) for x in df_sum[['bdr','adr']].head(PLOT_TOP_N).to_records(index=False))\n",
    "            plot_list = [p for p in processed if (p[0], p[1]) in top]\n",
    "\n",
    "        # Plots + Backtest por par\n",
    "        bt_rows = []\n",
    "        for bdr, adr, pq in plot_list:\n",
    "            df = pd.read_parquet(pq)\n",
    "            df = df.set_index(pd.to_datetime(df['datetime'])).drop(columns=['datetime'])\n",
    "            name = f\"{bdr}_{adr}\"\n",
    "\n",
    "            # Diagnósticos rápidos\n",
    "            diag = diagnostics_quick(df)\n",
    "            if not np.isfinite(diag['median_ratio']) or diag['median_ratio'] <= 0:\n",
    "                print(f\"[WARN][{name}] median_ratio inválido:\", diag['median_ratio'])\n",
    "\n",
    "            # Plots\n",
    "            plot_prices(df, name, OUT_DIR / \"plots\")\n",
    "            plot_spread(df, name, OUT_DIR / \"plots\")\n",
    "            plot_zscore(df, name, OUT_DIR / \"plots\")\n",
    "\n",
    "            # Backtest (ajuste custos/borrow conforme sua realidade)\n",
    "            bars_day = estimate_bars_per_day_from_index(df.index)\n",
    "            bt_df, bt_sum = backtest_spread(\n",
    "                df,\n",
    "                z_entry=2.0, z_exit=0.5, z_stop=3.0,        # z_exit > 0 evita saída instantânea\n",
    "                cost_bdr_bps=10.0, cost_synth_bps=2.0,\n",
    "                borrow_bdr_bps_day=40.0,\n",
    "                bars_per_day=bars_day,\n",
    "                flat_at_eod=True,\n",
    "                min_hold=2,                      # segurar pelo menos 2 barras\n",
    "                no_entry_last_k_bars=2,          # não entra nas 2 últimas barras\n",
    "                latency_bars=0                   # se quiser, teste =1\n",
    "            )\n",
    "            share = entries_near_eod_share(bt_df, df, last_k=2)\n",
    "            if np.isnan(share):\n",
    "                print(\"% de entradas nas últimas 2 barras do dia: N/A (sem entradas)\")\n",
    "            else:\n",
    "                print(f\"% de entradas nas últimas 2 barras do dia: {share:.1%}\")\n",
    "\n",
    "\n",
    "            # Salvar curva de PnL\n",
    "            bt_path = OUT_DIR / \"pairs\" / f\"{name}_bt.parquet\"\n",
    "            bt_df.reset_index().rename(columns={'index':'datetime'}).to_parquet(bt_path, index=False)\n",
    "\n",
    "\n",
    "            bt_rows.append({\n",
    "                'bdr': bdr, 'adr': adr,\n",
    "                **bt_sum,\n",
    "                'corr_log': diag['corr_log'],\n",
    "                'median_ratio_diag': diag['median_ratio']\n",
    "            })\n",
    "            print(f\"[BT] {name}: sharpe={bt_sum['sharpe_hourly_annualized']:.2f} | pnl={bt_sum['pnl_total']:.2f} | trades={bt_sum['trades']}\")\n",
    "\n",
    "        if bt_rows:\n",
    "            df_bt = pd.DataFrame(bt_rows).sort_values('sharpe_hourly_annualized', ascending=False)\n",
    "            df_bt.to_csv(OUT_DIR / \"summary_backtest.csv\", index=False, float_format=\"%.6f\")\n",
    "            print(\"\\n== Resultado do backtest (top 10 por Sharpe) ==\")\n",
    "            print(df_bt[['bdr','adr','sharpe_hourly_annualized','pnl_total','mdd','trades','winrate','corr_log']].head(10))\n",
    "        pairs_to_test = processed\n",
    "\n",
    "        df_grid = grid_search_params(\n",
    "            pairs_to_test=pairs_to_test,\n",
    "            z_entries=(1.5, 2.0, 2.5),\n",
    "            z_stops=(3.0, 3.5, 4.0),\n",
    "            cost_sets=((10.0, 2.0), (20.0, 5.0)),\n",
    "            borrow_daily_bps=(0.0, 20.0, 40.0),\n",
    "            flat_at_eod=True\n",
    "        )\n",
    "\n",
    "        if not df_grid.empty:\n",
    "            df_grid.to_csv(OUT_DIR / \"summary_gridsearch.csv\", index=False, float_format=\"%.6f\")\n",
    "            print(\"\\n== Grid search (top 10 por Sharpe) ==\")\n",
    "            print(df_grid[['pair','z_entry','z_stop','cost_bdr_bps','cost_syn_bps','borrow_bps_day',\n",
    "                        'sharpe_hourly_annualized','pnl_total','trades','winrate']].head(10))\n",
    "        else:\n",
    "            print(\"\\n[GRID] Nenhum cenário foi avaliado (lista 'pairs_to_test' vazia?).\")\n",
    "    else:\n",
    "        print(\"Nenhum par válido processado.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
